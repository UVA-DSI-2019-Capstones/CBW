{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xml_to_dataframe(xml_file_path, collection_id):\n",
    "    \n",
    "    data = open(xml_file_path,\"rb\")\n",
    "    tree = ET.parse (data)\n",
    "\n",
    "    #a007_data = open('a007.csv', 'w')\n",
    "\n",
    "    root=tree.getroot()\n",
    "    #import csv\n",
    "    #csvwriter = csv.writer(a007_data)\n",
    "    a007_head = []\n",
    "\n",
    "    member = root.find('div2')\n",
    "    \n",
    "    if(member == None):\n",
    "        member = root.find('text').find('body').find('div1').find('div2')\n",
    "    para_text = {}\n",
    "    \n",
    "    #if len(member.getchildren())==1:\n",
    "        #para_text['Para_no:'+each.get('n')] = each.text\n",
    "        #member.getchildren().get('n').text\n",
    "\n",
    "    #print(member)\n",
    "    for each in member:\n",
    "        #print(each)\n",
    "        if(each.tag == 'p'):\n",
    "            para_text['Para_no:'+each.get('n')] = each.text\n",
    "\n",
    "\n",
    "    \n",
    "    d1=pd.DataFrame.from_dict(data = para_text, orient = 'index')\n",
    "    d1\n",
    "\n",
    "    member = root.find('teiHeader')\n",
    "\n",
    "\n",
    "    book_title = member.getchildren()[0].getchildren()[0].getchildren()[0].text\n",
    "    author = member.getchildren()[0].getchildren()[0].getchildren()[1].text\n",
    "    \n",
    "    if len(member.getchildren()[0].getchildren()[1].getchildren())==2:\n",
    "        publisher = member.getchildren()[0].getchildren()[1].getchildren()[0].text\n",
    "        publisher2=member.getchildren()[0].getchildren()[1].getchildren()[1].text\n",
    "    else:\n",
    "        publisher = member.getchildren()[0].getchildren()[1].getchildren()[0].text\n",
    "        publisher2=\"None\"\n",
    "    \n",
    "    bio_id=root.getchildren()[1].get('id')\n",
    "    print(bio_id)\n",
    "    if bio_id == None:\n",
    "        print('entering loop')\n",
    "        bio_id = root.find('text').find('body').find('div1').find('div2').get('id')\n",
    "        print(bio_id)\n",
    "    \n",
    "    text_type=root.getchildren()[1].get('type')\n",
    "    \n",
    "    if text_type == None:\n",
    "        print(text_type)\n",
    "    \n",
    "    bio_title=root.getchildren()[1].getchildren()[0].getchildren()[0].text.strip()\n",
    "    \n",
    "    if bio_title == \"\":\n",
    "        bio_title = root.find('text').find('body').find('div1').find('div2').find('head').find('hi').text.strip()\n",
    "        \n",
    "    \n",
    "    \n",
    "    d = {'Book_title':book_title, 'Collection_Id': collection_id, 'Author':author,\n",
    "         'Publisher1':publisher, 'Publisher2':publisher2, 'Biography_id':bio_id,\n",
    "         'Text_type':text_type, 'Biography_title':bio_title}\n",
    "   # print(d)\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(d, index=[0])\n",
    "    df\n",
    "\n",
    "    d1 = pd.DataFrame(d1)\n",
    "    #d1.reset_index(drop= True)\n",
    "    df.head()\n",
    "\n",
    "    #Repeating the dataframe for nubmer of paragraphs\n",
    "    df_1 = pd.concat([df]*d1.shape[0],ignore_index = True)\n",
    "\n",
    "    #Cbind here\n",
    "    d1['Para_no'] = d1.index\n",
    "    combined_df = pd.concat([d1.reset_index(drop = True),df_1], axis = 1)\n",
    "    \n",
    "    return(combined_df)\n",
    "#xml_file_path=\"/Users/user/Documents/capstone/data/books/a007/bio12/a007bio12.xml\"\n",
    "#xml_to_dataframe(xml_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a007\n",
      "bio12\n",
      "a007\n",
      "bio13\n",
      "a001\n",
      "bio04\n",
      "a001\n",
      "bio20\n",
      "a001\n",
      "bio70\n",
      "a624\n",
      "bio26\n",
      "a411\n",
      "bio23\n",
      "a630\n",
      "None\n",
      "entering loop\n",
      "bio05\n",
      "None\n",
      "a863\n",
      "None\n",
      "entering loop\n",
      "bio11\n",
      "None\n",
      "a863\n",
      "bio14\n"
     ]
    }
   ],
   "source": [
    "path_overall = '/Users/user/Documents/capstone/data/books'\n",
    "#Initializing an empty data frame\n",
    "xml_df_all = pd.DataFrame()\n",
    "\n",
    "### Looping through each of the collective biography\n",
    "for a_files in os.listdir(path_overall):\n",
    "    #print(a_files)\n",
    "    if(os.path.isdir(path_overall+\"//\"+a_files)):\n",
    "        #print(\"entering\")\n",
    "        ### Looping through each of the individual biography\n",
    "        for bio_files in os.listdir(path_overall+\"//\"+a_files):\n",
    "            \n",
    "            #print(os.path.isdir(path_overall+\"\\\\\"+a_files))\n",
    "            if(os.path.isdir(path_overall+\"//\"+a_files+\"//\"+bio_files)):\n",
    "                \n",
    "                files = os.listdir(path_overall+\"//\"+a_files+\"//\"+bio_files)\n",
    "                #print(bio_files)\n",
    "                #print(files)\n",
    "                xml_files = [each_file for each_file in files if \".xml\" in each_file and \".bess\" not in each_file]\n",
    "                ### Looping through each of the valid file in an individual biography\n",
    "                for each_xml_file in xml_files:\n",
    "                    #print(each_xml_file)\n",
    "                    xml_file_path  = path_overall+\"//\"+a_files+\"//\"+bio_files+\"//\"+each_xml_file\n",
    "                    collection_id = a_files[:4]\n",
    "                    print(collection_id)\n",
    "                    xml_df_current = xml_to_dataframe(xml_file_path, collection_id)\n",
    "                    xml_df_all = pd.concat([xml_df_all,xml_df_current],axis = 0)\n",
    "                    xml_df_all.reset_index(drop = True, inplace= True)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.DataFrame(xml_df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"metadata_fewfiles.csv\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/user\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
