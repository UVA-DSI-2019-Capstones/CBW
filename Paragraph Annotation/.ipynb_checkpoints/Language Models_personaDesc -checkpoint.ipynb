{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reading input datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Reading the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CollectionID</th>\n",
       "      <th>BiographyID</th>\n",
       "      <th>ParagraphNo</th>\n",
       "      <th>ParagraphText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a001</td>\n",
       "      <td>bio04</td>\n",
       "      <td>1</td>\n",
       "      <td>A FRENCH philosopher, moralizing on the great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a001</td>\n",
       "      <td>bio04</td>\n",
       "      <td>2</td>\n",
       "      <td>Cleopatra was joint heir to the throne of Egyp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a001</td>\n",
       "      <td>bio04</td>\n",
       "      <td>3</td>\n",
       "      <td>Cleopatra might have responded with a brillian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a001</td>\n",
       "      <td>bio04</td>\n",
       "      <td>4</td>\n",
       "      <td>Caesar was then above fifty years of age. His ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a001</td>\n",
       "      <td>bio04</td>\n",
       "      <td>5</td>\n",
       "      <td>For three years Cleopatra reigned with little ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CollectionID BiographyID  ParagraphNo  \\\n",
       "0         a001       bio04            1   \n",
       "1         a001       bio04            2   \n",
       "2         a001       bio04            3   \n",
       "3         a001       bio04            4   \n",
       "4         a001       bio04            5   \n",
       "\n",
       "                                       ParagraphText  \n",
       "0  A FRENCH philosopher, moralizing on the great ...  \n",
       "1  Cleopatra was joint heir to the throne of Egyp...  \n",
       "2  Cleopatra might have responded with a brillian...  \n",
       "3  Caesar was then above fifty years of age. His ...  \n",
       "4  For three years Cleopatra reigned with little ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data_sentence = pd.read_csv('/Users/user/Documents/github/CBW/data/textdatanew.csv', encoding='ISO-8859-1')\n",
    "text_data_sentence.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Reading the text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (11,12,15,16,22,23,24,29,30,31,32,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CollectionID</th>\n",
       "      <th>BiographyID</th>\n",
       "      <th>ParagraphNo</th>\n",
       "      <th>sadness</th>\n",
       "      <th>joy</th>\n",
       "      <th>fear</th>\n",
       "      <th>disgust</th>\n",
       "      <th>anger</th>\n",
       "      <th>score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>...</th>\n",
       "      <th>Number</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Person</th>\n",
       "      <th>PrintMedia</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Sport</th>\n",
       "      <th>SportingEvent</th>\n",
       "      <th>TelevisionShow</th>\n",
       "      <th>Time</th>\n",
       "      <th>Vehicle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a001</td>\n",
       "      <td>bio04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.255896</td>\n",
       "      <td>0.558011</td>\n",
       "      <td>0.101166</td>\n",
       "      <td>0.111615</td>\n",
       "      <td>0.054668</td>\n",
       "      <td>0.290669</td>\n",
       "      <td>positive</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a001</td>\n",
       "      <td>bio04</td>\n",
       "      <td>2</td>\n",
       "      <td>0.171629</td>\n",
       "      <td>0.257088</td>\n",
       "      <td>0.173474</td>\n",
       "      <td>0.098726</td>\n",
       "      <td>0.267978</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Roman senate</td>\n",
       "      <td>Cleopatra, Julius Caesar, Pompey, Ptolemy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  CollectionID BiographyID  ParagraphNo   sadness       joy      fear  \\\n",
       "0         a001       bio04            1  0.255896  0.558011  0.101166   \n",
       "1         a001       bio04            2  0.171629  0.257088  0.173474   \n",
       "\n",
       "    disgust     anger     score sentiment   ...   Number  Organization  \\\n",
       "0  0.111615  0.054668  0.290669  positive   ...      NaN           NaN   \n",
       "1  0.098726  0.267978  0.000000   neutral   ...      NaN  Roman senate   \n",
       "\n",
       "                                      Person PrintMedia Quantity Sport  \\\n",
       "0                                  Cleopatra        NaN      NaN   NaN   \n",
       "1  Cleopatra, Julius Caesar, Pompey, Ptolemy        NaN      NaN   NaN   \n",
       "\n",
       "  SportingEvent TelevisionShow Time Vehicle  \n",
       "0           NaN            NaN  NaN     NaN  \n",
       "1           NaN            NaN  NaN     NaN  \n",
       "\n",
       "[2 rows x 34 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_features = pd.read_csv(\"/Users/user/Documents/github/CBW/data/text_features.csv\", encoding='ISO-8859-1')\n",
    "text_features.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Reading the Response file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Event</th>\n",
       "      <th>Type</th>\n",
       "      <th>para no</th>\n",
       "      <th>URI</th>\n",
       "      <th>author</th>\n",
       "      <th>biographyID</th>\n",
       "      <th>collectionID</th>\n",
       "      <th>personaName</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>after</td>\n",
       "      <td>name</td>\n",
       "      <td>stageOfLife</td>\n",
       "      <td>1.0</td>\n",
       "      <td>a001.bio04.bess.xml</td>\n",
       "      <td>Willis John Abbot</td>\n",
       "      <td>bio04</td>\n",
       "      <td>a001</td>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>Cleopatra (B.C. 69-30): The World's Most Famou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>culmination</td>\n",
       "      <td>name</td>\n",
       "      <td>stageOfLife</td>\n",
       "      <td>1.0</td>\n",
       "      <td>a001.bio04.bess.xml</td>\n",
       "      <td>Willis John Abbot</td>\n",
       "      <td>bio04</td>\n",
       "      <td>a001</td>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>Cleopatra (B.C. 69-30): The World's Most Famou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>middle</td>\n",
       "      <td>name</td>\n",
       "      <td>stageOfLife</td>\n",
       "      <td>2.0</td>\n",
       "      <td>a001.bio04.bess.xml</td>\n",
       "      <td>Willis John Abbot</td>\n",
       "      <td>bio04</td>\n",
       "      <td>a001</td>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>Cleopatra (B.C. 69-30): The World's Most Famou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>middle</td>\n",
       "      <td>name</td>\n",
       "      <td>stageOfLife</td>\n",
       "      <td>3.0</td>\n",
       "      <td>a001.bio04.bess.xml</td>\n",
       "      <td>Willis John Abbot</td>\n",
       "      <td>bio04</td>\n",
       "      <td>a001</td>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>Cleopatra (B.C. 69-30): The World's Most Famou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>middle</td>\n",
       "      <td>name</td>\n",
       "      <td>stageOfLife</td>\n",
       "      <td>4.0</td>\n",
       "      <td>a001.bio04.bess.xml</td>\n",
       "      <td>Willis John Abbot</td>\n",
       "      <td>bio04</td>\n",
       "      <td>a001</td>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>Cleopatra (B.C. 69-30): The World's Most Famou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Content Event         Type  para no                  URI  \\\n",
       "0        after  name  stageOfLife      1.0  a001.bio04.bess.xml   \n",
       "1  culmination  name  stageOfLife      1.0  a001.bio04.bess.xml   \n",
       "2       middle  name  stageOfLife      2.0  a001.bio04.bess.xml   \n",
       "3       middle  name  stageOfLife      3.0  a001.bio04.bess.xml   \n",
       "4       middle  name  stageOfLife      4.0  a001.bio04.bess.xml   \n",
       "\n",
       "              author biographyID collectionID personaName  \\\n",
       "0  Willis John Abbot       bio04         a001   Cleopatra   \n",
       "1  Willis John Abbot       bio04         a001   Cleopatra   \n",
       "2  Willis John Abbot       bio04         a001   Cleopatra   \n",
       "3  Willis John Abbot       bio04         a001   Cleopatra   \n",
       "4  Willis John Abbot       bio04         a001   Cleopatra   \n",
       "\n",
       "                                               title  \n",
       "0  Cleopatra (B.C. 69-30): The World's Most Famou...  \n",
       "1  Cleopatra (B.C. 69-30): The World's Most Famou...  \n",
       "2  Cleopatra (B.C. 69-30): The World's Most Famou...  \n",
       "3  Cleopatra (B.C. 69-30): The World's Most Famou...  \n",
       "4  Cleopatra (B.C. 69-30): The World's Most Famou...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bess_tags = pd.read_csv('/Users/user/Documents/github/CBW/data/CBW_Bess_tags_final2.csv')\n",
    "bess_tags.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Getting the top personaDesc types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bess_reponse = bess_tags.loc[:,['Content','Event','Type','para no','biographyID','collectionID']]\n",
    "\n",
    "bess_reponse= bess_reponse.fillna(' ')\n",
    "\n",
    "bess_reponse.loc[:,'Response'] = bess_reponse.loc[:,['Content','Event']].apply(lambda x: '_'.join(x),axis = 1)\n",
    "\n",
    "bess_reponse['Bio_col_id'] = bess_reponse['biographyID'] +\"_\" + bess_reponse['collectionID']\n",
    "bess_reponse['Bio_col_para_id'] = bess_reponse['Bio_col_id'] +\"_\" + bess_reponse['para no'].astype('str')\n",
    "\n",
    "doc_count = pd.DataFrame(bess_reponse[bess_reponse.Type.isin(['personaDescription'])].\\\n",
    "                         groupby(['Response'])['Bio_col_id'].apply(lambda x: len(np.unique(x))))\n",
    "\n",
    "#############################################################################\n",
    "##########TF - IDF Approach to get the top event types ######################\n",
    "#############################################################################\n",
    "\n",
    "term_freq = pd.DataFrame(bess_reponse[bess_reponse.Type.isin(['personaDescription'])].\\\n",
    "                            groupby(['Response'])['Bio_col_id'].count())\n",
    "\n",
    "total_docs = len(bess_reponse['Bio_col_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term_freq</th>\n",
       "      <th>Doc_freq</th>\n",
       "      <th>tf_idf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Response</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beautiful_type</th>\n",
       "      <td>538</td>\n",
       "      <td>157</td>\n",
       "      <td>359.028542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dedicated or devoted_type</th>\n",
       "      <td>403</td>\n",
       "      <td>137</td>\n",
       "      <td>323.852483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self-sacrificing_type</th>\n",
       "      <td>214</td>\n",
       "      <td>73</td>\n",
       "      <td>306.688891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>energetic or untiring_type</th>\n",
       "      <td>343</td>\n",
       "      <td>128</td>\n",
       "      <td>298.943309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>faith, confident in_type</th>\n",
       "      <td>181</td>\n",
       "      <td>68</td>\n",
       "      <td>272.238009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loving_type</th>\n",
       "      <td>236</td>\n",
       "      <td>97</td>\n",
       "      <td>271.134293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>devout_type</th>\n",
       "      <td>176</td>\n",
       "      <td>70</td>\n",
       "      <td>259.615815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skilled, in occupation_type</th>\n",
       "      <td>228</td>\n",
       "      <td>100</td>\n",
       "      <td>254.998601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brave_type</th>\n",
       "      <td>332</td>\n",
       "      <td>142</td>\n",
       "      <td>254.895671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happy_type</th>\n",
       "      <td>293</td>\n",
       "      <td>131</td>\n",
       "      <td>248.577619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>physically weak or frail_type</th>\n",
       "      <td>149</td>\n",
       "      <td>61</td>\n",
       "      <td>240.293974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beloved_type</th>\n",
       "      <td>193</td>\n",
       "      <td>89</td>\n",
       "      <td>238.345105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cheerful_type</th>\n",
       "      <td>180</td>\n",
       "      <td>83</td>\n",
       "      <td>234.854009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sympathetic_type</th>\n",
       "      <td>225</td>\n",
       "      <td>108</td>\n",
       "      <td>234.327122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>willful or stubborn_type</th>\n",
       "      <td>177</td>\n",
       "      <td>82</td>\n",
       "      <td>233.085256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>persistent_type</th>\n",
       "      <td>150</td>\n",
       "      <td>66</td>\n",
       "      <td>230.089554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>physically strong_type</th>\n",
       "      <td>142</td>\n",
       "      <td>61</td>\n",
       "      <td>229.004996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>charming_type</th>\n",
       "      <td>197</td>\n",
       "      <td>100</td>\n",
       "      <td>220.327738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>famous_type</th>\n",
       "      <td>159</td>\n",
       "      <td>78</td>\n",
       "      <td>217.333328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>charitable_type</th>\n",
       "      <td>138</td>\n",
       "      <td>64</td>\n",
       "      <td>215.928879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Term_freq  Doc_freq      tf_idf\n",
       "Response                                                      \n",
       "beautiful_type                       538       157  359.028542\n",
       "dedicated or devoted_type            403       137  323.852483\n",
       "self-sacrificing_type                214        73  306.688891\n",
       "energetic or untiring_type           343       128  298.943309\n",
       "faith, confident in_type             181        68  272.238009\n",
       "loving_type                          236        97  271.134293\n",
       "devout_type                          176        70  259.615815\n",
       "skilled, in occupation_type          228       100  254.998601\n",
       "brave_type                           332       142  254.895671\n",
       "happy_type                           293       131  248.577619\n",
       "physically weak or frail_type        149        61  240.293974\n",
       "beloved_type                         193        89  238.345105\n",
       "cheerful_type                        180        83  234.854009\n",
       "sympathetic_type                     225       108  234.327122\n",
       "willful or stubborn_type             177        82  233.085256\n",
       "persistent_type                      150        66  230.089554\n",
       "physically strong_type               142        61  229.004996\n",
       "charming_type                        197       100  220.327738\n",
       "famous_type                          159        78  217.333328\n",
       "charitable_type                      138        64  215.928879"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_by_counts = pd.concat([term_freq,doc_count],axis = 1)\n",
    "\n",
    "group_by_counts.columns = ['Term_freq','Doc_freq']\n",
    "group_by_counts['tf_idf'] = pd.DataFrame(group_by_counts['Term_freq'] * np.log(total_docs/group_by_counts['Doc_freq']) )\n",
    "\n",
    "group_by_counts.sort_values(['tf_idf'],ascending=False)[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bio_response = pd.DataFrame(bess_reponse.groupby(['Response'])['Bio_col_para_id'].apply(lambda x: len(np.unique(x))))\n",
    "# bio_response.sort_values(['Bio_col_para_id'],ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Creating the Respone Variable for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Select the event for building the model\n",
    "reponse_required = 'beautiful_type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "reponse_required_to_merge = bess_reponse[bess_reponse.Response == reponse_required]\n",
    "\n",
    "text_data_sentence.ParagraphNo = text_data_sentence.ParagraphNo.astype('int')\n",
    "reponse_required_to_merge['para no'] = reponse_required_to_merge['para no'].astype('int')\n",
    "##### Merging the features and the response dataset\n",
    "text_data_merge = pd.merge(text_data_sentence, reponse_required_to_merge.drop_duplicates(),\\\n",
    "                     how = 'left', left_on=['CollectionID','BiographyID','ParagraphNo'],\n",
    "                         right_on=['collectionID','biographyID','para no'])\n",
    "\n",
    "\n",
    "########## Final Data Frame #############\n",
    "final_data_frame = text_data_merge.loc[:,['ParagraphText','Response']]\n",
    "\n",
    "final_data_frame['Response_binary'] = np.where(final_data_frame.Response.isnull(),0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Distribution of the Response variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16107\n",
       "1      530\n",
       "Name: Response_binary, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data_frame.Response_binary.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Prepocessing the Paragraph Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.1 StopWord collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting stop words - High Frequency and Low Frequency word list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "tokenized_para = final_data_frame.ParagraphText.apply(word_tokenize)\n",
    "\n",
    "all_sent = [words for each_sent in tokenized_para for words in each_sent]\n",
    "\n",
    "count_dict = Counter(all_sent)\n",
    "\n",
    "high_freq_words = [word for (word,count) in count_dict.most_common(500)]\n",
    "\n",
    "less_freq_words = []\n",
    "threshold = 5\n",
    "\n",
    "for k,v in count_dict.items():\n",
    "    \n",
    "    if v < threshold:\n",
    "        less_freq_words.append(k)\n",
    "\n",
    "        \n",
    "######### List of all stop words ##########\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(high_freq_words)\n",
    "stop_words.extend(less_freq_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Creating Training and Test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(final_data_frame.ParagraphText ,final_data_frame.Response_binary,\n",
    "                                                    test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Splitting the dataset into two categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bin_1 = X_train[y_train == 1]\n",
    "data_bin_0 = X_train[y_train == 0]\n",
    "\n",
    "dict_bin_1_tokens = word_tokenize(' '.join(data_bin_1))\n",
    "dict_bin_0_tokens = word_tokenize(' '.join(data_bin_0))\n",
    "\n",
    "dictionary_bin_1 = Counter([each for each in dict_bin_1_tokens if each not in stop_words])\n",
    "dictionary_bin_0 = Counter([each for each in dict_bin_0_tokens if each not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Creating a dataframe of probabilites ######################\n",
    "vocab_size = sum(dictionary_bin_1.values())\n",
    "for k,v in dictionary_bin_1.items():\n",
    "    dictionary_bin_1[k] = v/vocab_size\n",
    "    \n",
    "vocab_size_0 = sum(dictionary_bin_0.values())\n",
    "for k_0,v_0 in dictionary_bin_0.items():\n",
    "    dictionary_bin_0[k_0] = v_0/vocab_size_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Creating a dictionary of all the words in each of the binary category 1 and 0 ##############\n",
    "\n",
    "bin_1_value = X_test.apply(lambda x: \\\n",
    "                           sum([dictionary_bin_1[each] if (each in dictionary_bin_1.keys() and each not in stop_words)\\\n",
    "                                else 0 for each in word_tokenize(x)]))\n",
    "\n",
    "bin_0_value = X_test.apply(lambda x: \\\n",
    "                           sum([dictionary_bin_0[each] if (each in dictionary_bin_0.keys() and each not in stop_words)\\\n",
    "                                else 0 for each in word_tokenize(x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame([bin_1_value,bin_0_value]).T\n",
    "df_result.columns = ['bin_1_value','bin_0_value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Language Model Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1274"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_result.bin_0_value < df_result.bin_1_value).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Accuracy and Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.28125"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * (df_result.bin_0_value < df_result.bin_1_value).sum()/len(df_result.bin_1_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3229\n",
       "1      99\n",
       "Name: Response_binary, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6415264423076923"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "preds = (df_result.bin_0_value < df_result.bin_1_value).astype('int')\n",
    "(preds == y_test).sum()/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2045, 1184],\n",
       "       [   9,   90]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin_1_value</th>\n",
       "      <th>bin_0_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13128</th>\n",
       "      <td>0.004890</td>\n",
       "      <td>0.003756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7057</th>\n",
       "      <td>0.014719</td>\n",
       "      <td>0.014046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5704</th>\n",
       "      <td>0.033262</td>\n",
       "      <td>0.032548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4664</th>\n",
       "      <td>0.005713</td>\n",
       "      <td>0.005036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.005810</td>\n",
       "      <td>0.005628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bin_1_value  bin_0_value\n",
       "13128     0.004890     0.003756\n",
       "7057      0.014719     0.014046\n",
       "5704      0.033262     0.032548\n",
       "4664      0.005713     0.005036\n",
       "142       0.005810     0.005628"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result[df_result.bin_0_value < df_result.bin_1_value].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Considering the words with higher probability in 1 and 0\n",
    "\n",
    "primary_words = []\n",
    "\n",
    "for each in dictionary_bin_0.keys():\n",
    "    if dictionary_bin_0[each] < dictionary_bin_1[each]:\n",
    "        primary_words.append(each)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Significant Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['courage',\n",
       " 'stuck',\n",
       " 'ostensibly',\n",
       " 'ton',\n",
       " 'gentle-',\n",
       " 'union',\n",
       " 'probably',\n",
       " 'hunt',\n",
       " 'sovereign']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primary_words[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Modification - Including the words that are present for the binary class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bin_1 = X_train[y_train == 1]\n",
    "data_bin_0 = X_train[y_train == 0]\n",
    "\n",
    "dict_bin_1_tokens = word_tokenize(' '.join(data_bin_1))\n",
    "dict_bin_0_tokens = word_tokenize(' '.join(data_bin_0))\n",
    "\n",
    "dictionary_bin_1 = Counter([each for each in dict_bin_1_tokens if each not in stop_words])\n",
    "dictionary_bin_0 = Counter([each for each in dict_bin_0_tokens if each not in stop_words and each in dict_bin_1_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Creating a dataframe of probabilites ######################\n",
    "\n",
    "vocab_size = sum(dictionary_bin_1.values())\n",
    "for k,v in dictionary_bin_1.items():\n",
    "    dictionary_bin_1[k] = v/vocab_size\n",
    "    \n",
    "vocab_size_0 = sum(dictionary_bin_0.values())\n",
    "for k_0,v_0 in dictionary_bin_0.items():\n",
    "    dictionary_bin_0[k_0] = v_0/vocab_size_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Creating a dictionary of all the words in each of the binary category 1 and 0 ##############\n",
    "\n",
    "bin_1_value = X_test.apply(lambda x: \\\n",
    "                           sum([dictionary_bin_1[each] if (each in dictionary_bin_1.keys() and each not in stop_words)\\\n",
    "                                else 0 for each in word_tokenize(x)]))\n",
    "\n",
    "bin_0_value = X_test.apply(lambda x: \\\n",
    "                           sum([dictionary_bin_0[each] if (each in dictionary_bin_0.keys() and each not in stop_words)\\\n",
    "                                else 0 for each in word_tokenize(x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame([bin_1_value,bin_0_value]).T\n",
    "df_result.columns = ['bin_1_value','bin_0_value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Language Model Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "465"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_result.bin_0_value < df_result.bin_1_value).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3229\n",
       "1      99\n",
       "Name: Response_binary, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8665865384615384"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "preds = (df_result.bin_0_value < df_result.bin_1_value).astype('int')\n",
    "(preds == y_test).sum()/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2824,  405],\n",
       "       [  39,   60]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin_1_value</th>\n",
       "      <th>bin_0_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13128</th>\n",
       "      <td>0.004890</td>\n",
       "      <td>0.004762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4384</th>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.000292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10243</th>\n",
       "      <td>0.014331</td>\n",
       "      <td>0.009127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13743</th>\n",
       "      <td>0.002130</td>\n",
       "      <td>0.002080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10356</th>\n",
       "      <td>0.014283</td>\n",
       "      <td>0.014111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bin_1_value  bin_0_value\n",
       "13128     0.004890     0.004762\n",
       "4384      0.000387     0.000292\n",
       "10243     0.014331     0.009127\n",
       "13743     0.002130     0.002080\n",
       "10356     0.014283     0.014111"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result[df_result.bin_0_value < df_result.bin_1_value].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Considering the words with higher probability in 1 and 0\n",
    "\n",
    "primary_words = []\n",
    "\n",
    "for each in dictionary_bin_0.keys():\n",
    "    if dictionary_bin_0[each] < dictionary_bin_1[each]:\n",
    "        primary_words.append(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ostensibly',\n",
       " 'gentle-',\n",
       " 'union',\n",
       " 'hunt',\n",
       " 'sovereign',\n",
       " 'recognize',\n",
       " 'blood',\n",
       " 'mistress',\n",
       " 'rapt']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primary_words[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
