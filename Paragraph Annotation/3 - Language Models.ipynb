{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reading input datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Reading the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CollectionID</th>\n",
       "      <th>BiographyID</th>\n",
       "      <th>ParagraphNo</th>\n",
       "      <th>ParagraphText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a001</td>\n",
       "      <td>bio04</td>\n",
       "      <td>1</td>\n",
       "      <td>A FRENCH philosopher, moralizing on the great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a001</td>\n",
       "      <td>bio04</td>\n",
       "      <td>2</td>\n",
       "      <td>Cleopatra was joint heir to the throne of Egyp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a001</td>\n",
       "      <td>bio04</td>\n",
       "      <td>3</td>\n",
       "      <td>Cleopatra might have responded with a brillian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a001</td>\n",
       "      <td>bio04</td>\n",
       "      <td>4</td>\n",
       "      <td>Caesar was then above fifty years of age. His ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a001</td>\n",
       "      <td>bio04</td>\n",
       "      <td>5</td>\n",
       "      <td>For three years Cleopatra reigned with little ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CollectionID BiographyID  ParagraphNo  \\\n",
       "0         a001       bio04            1   \n",
       "1         a001       bio04            2   \n",
       "2         a001       bio04            3   \n",
       "3         a001       bio04            4   \n",
       "4         a001       bio04            5   \n",
       "\n",
       "                                       ParagraphText  \n",
       "0  A FRENCH philosopher, moralizing on the great ...  \n",
       "1  Cleopatra was joint heir to the throne of Egyp...  \n",
       "2  Cleopatra might have responded with a brillian...  \n",
       "3  Caesar was then above fifty years of age. His ...  \n",
       "4  For three years Cleopatra reigned with little ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data_sentence = pd.read_csv('./Files/textdatanew.csv', encoding='ISO-8859-1')\n",
    "text_data_sentence.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Reading the text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arvra\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (11,12,15,16,22,23,24,29,30,31,32,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CollectionID</th>\n",
       "      <th>BiographyID</th>\n",
       "      <th>ParagraphNo</th>\n",
       "      <th>sadness</th>\n",
       "      <th>joy</th>\n",
       "      <th>fear</th>\n",
       "      <th>disgust</th>\n",
       "      <th>anger</th>\n",
       "      <th>score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>...</th>\n",
       "      <th>Number</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Person</th>\n",
       "      <th>PrintMedia</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Sport</th>\n",
       "      <th>SportingEvent</th>\n",
       "      <th>TelevisionShow</th>\n",
       "      <th>Time</th>\n",
       "      <th>Vehicle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a001</td>\n",
       "      <td>bio04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.255896</td>\n",
       "      <td>0.558011</td>\n",
       "      <td>0.101166</td>\n",
       "      <td>0.111615</td>\n",
       "      <td>0.054668</td>\n",
       "      <td>0.290669</td>\n",
       "      <td>positive</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a001</td>\n",
       "      <td>bio04</td>\n",
       "      <td>2</td>\n",
       "      <td>0.171629</td>\n",
       "      <td>0.257088</td>\n",
       "      <td>0.173474</td>\n",
       "      <td>0.098726</td>\n",
       "      <td>0.267978</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Roman senate</td>\n",
       "      <td>Cleopatra, Julius Caesar, Pompey, Ptolemy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  CollectionID BiographyID  ParagraphNo   sadness       joy      fear  \\\n",
       "0         a001       bio04            1  0.255896  0.558011  0.101166   \n",
       "1         a001       bio04            2  0.171629  0.257088  0.173474   \n",
       "\n",
       "    disgust     anger     score sentiment   ...   Number  Organization  \\\n",
       "0  0.111615  0.054668  0.290669  positive   ...      NaN           NaN   \n",
       "1  0.098726  0.267978  0.000000   neutral   ...      NaN  Roman senate   \n",
       "\n",
       "                                      Person PrintMedia Quantity Sport  \\\n",
       "0                                  Cleopatra        NaN      NaN   NaN   \n",
       "1  Cleopatra, Julius Caesar, Pompey, Ptolemy        NaN      NaN   NaN   \n",
       "\n",
       "  SportingEvent TelevisionShow Time Vehicle  \n",
       "0           NaN            NaN  NaN     NaN  \n",
       "1           NaN            NaN  NaN     NaN  \n",
       "\n",
       "[2 rows x 34 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_features = pd.read_csv(\"text_features.csv\", encoding='ISO-8859-1')\n",
    "text_features.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Reading the Response file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Event</th>\n",
       "      <th>Type</th>\n",
       "      <th>para no</th>\n",
       "      <th>URI</th>\n",
       "      <th>author</th>\n",
       "      <th>biographyID</th>\n",
       "      <th>collectionID</th>\n",
       "      <th>personaName</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>after</td>\n",
       "      <td>name</td>\n",
       "      <td>stageOfLife</td>\n",
       "      <td>1.0</td>\n",
       "      <td>a001.bio04.bess.xml</td>\n",
       "      <td>Willis John Abbot</td>\n",
       "      <td>bio04</td>\n",
       "      <td>a001</td>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>Cleopatra (B.C. 69-30): The World's Most Famou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>culmination</td>\n",
       "      <td>name</td>\n",
       "      <td>stageOfLife</td>\n",
       "      <td>1.0</td>\n",
       "      <td>a001.bio04.bess.xml</td>\n",
       "      <td>Willis John Abbot</td>\n",
       "      <td>bio04</td>\n",
       "      <td>a001</td>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>Cleopatra (B.C. 69-30): The World's Most Famou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>middle</td>\n",
       "      <td>name</td>\n",
       "      <td>stageOfLife</td>\n",
       "      <td>2.0</td>\n",
       "      <td>a001.bio04.bess.xml</td>\n",
       "      <td>Willis John Abbot</td>\n",
       "      <td>bio04</td>\n",
       "      <td>a001</td>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>Cleopatra (B.C. 69-30): The World's Most Famou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>middle</td>\n",
       "      <td>name</td>\n",
       "      <td>stageOfLife</td>\n",
       "      <td>3.0</td>\n",
       "      <td>a001.bio04.bess.xml</td>\n",
       "      <td>Willis John Abbot</td>\n",
       "      <td>bio04</td>\n",
       "      <td>a001</td>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>Cleopatra (B.C. 69-30): The World's Most Famou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>middle</td>\n",
       "      <td>name</td>\n",
       "      <td>stageOfLife</td>\n",
       "      <td>4.0</td>\n",
       "      <td>a001.bio04.bess.xml</td>\n",
       "      <td>Willis John Abbot</td>\n",
       "      <td>bio04</td>\n",
       "      <td>a001</td>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>Cleopatra (B.C. 69-30): The World's Most Famou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Content Event         Type  para no                  URI  \\\n",
       "0        after  name  stageOfLife      1.0  a001.bio04.bess.xml   \n",
       "1  culmination  name  stageOfLife      1.0  a001.bio04.bess.xml   \n",
       "2       middle  name  stageOfLife      2.0  a001.bio04.bess.xml   \n",
       "3       middle  name  stageOfLife      3.0  a001.bio04.bess.xml   \n",
       "4       middle  name  stageOfLife      4.0  a001.bio04.bess.xml   \n",
       "\n",
       "              author biographyID collectionID personaName  \\\n",
       "0  Willis John Abbot       bio04         a001   Cleopatra   \n",
       "1  Willis John Abbot       bio04         a001   Cleopatra   \n",
       "2  Willis John Abbot       bio04         a001   Cleopatra   \n",
       "3  Willis John Abbot       bio04         a001   Cleopatra   \n",
       "4  Willis John Abbot       bio04         a001   Cleopatra   \n",
       "\n",
       "                                               title  \n",
       "0  Cleopatra (B.C. 69-30): The World's Most Famou...  \n",
       "1  Cleopatra (B.C. 69-30): The World's Most Famou...  \n",
       "2  Cleopatra (B.C. 69-30): The World's Most Famou...  \n",
       "3  Cleopatra (B.C. 69-30): The World's Most Famou...  \n",
       "4  Cleopatra (B.C. 69-30): The World's Most Famou...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bess_tags = pd.read_csv('CBW_Bess_tags_final2.csv')\n",
    "bess_tags.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Getting the top Event types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bess_reponse = bess_tags.loc[:,['Content','Event','Type','para no','biographyID','collectionID']]\n",
    "\n",
    "bess_reponse= bess_reponse.fillna(' ')\n",
    "\n",
    "bess_reponse.loc[:,'Response'] = bess_reponse.loc[:,['Content','Event']].apply(lambda x: '_'.join(x),axis = 1)\n",
    "\n",
    "bess_reponse['Bio_col_id'] = bess_reponse['biographyID'] +\"_\" + bess_reponse['collectionID']\n",
    "bess_reponse['Bio_col_para_id'] = bess_reponse['Bio_col_id'] +\"_\" + bess_reponse['para no'].astype('str')\n",
    "\n",
    "doc_count = pd.DataFrame(bess_reponse[bess_reponse.Type.isin(['Event'])].\\\n",
    "                         groupby(['Response'])['Bio_col_id'].apply(lambda x: len(np.unique(x))))\n",
    "\n",
    "#############################################################################\n",
    "##########TF - IDF Approach to get the top event types ######################\n",
    "#############################################################################\n",
    "\n",
    "term_freq = pd.DataFrame(bess_reponse[bess_reponse.Type.isin(['Event'])].\\\n",
    "                            groupby(['Response'])['Bio_col_id'].count())\n",
    "\n",
    "total_docs = len(bess_reponse['Bio_col_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term_freq</th>\n",
       "      <th>Doc_freq</th>\n",
       "      <th>tf_idf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Response</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lover, male, named_agentType</th>\n",
       "      <td>776</td>\n",
       "      <td>75</td>\n",
       "      <td>1091.131263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hospital_locationStructure</th>\n",
       "      <td>617</td>\n",
       "      <td>71</td>\n",
       "      <td>901.378524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sovereign, male_agentType</th>\n",
       "      <td>655</td>\n",
       "      <td>79</td>\n",
       "      <td>886.959898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nobleman, named_agentType</th>\n",
       "      <td>853</td>\n",
       "      <td>122</td>\n",
       "      <td>784.388141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>husband_agentType</th>\n",
       "      <td>1245</td>\n",
       "      <td>165</td>\n",
       "      <td>768.961337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>royalty, male_agentType</th>\n",
       "      <td>753</td>\n",
       "      <td>111</td>\n",
       "      <td>763.583340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conversation_type</th>\n",
       "      <td>1118</td>\n",
       "      <td>171</td>\n",
       "      <td>650.588288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nursing, professional_type</th>\n",
       "      <td>281</td>\n",
       "      <td>33</td>\n",
       "      <td>625.808789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>famous man_agentType</th>\n",
       "      <td>712</td>\n",
       "      <td>129</td>\n",
       "      <td>615.006161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>officer, military_agentType</th>\n",
       "      <td>540</td>\n",
       "      <td>98</td>\n",
       "      <td>614.853517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theater_locationStructure</th>\n",
       "      <td>296</td>\n",
       "      <td>55</td>\n",
       "      <td>508.010567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love affair_type</th>\n",
       "      <td>400</td>\n",
       "      <td>86</td>\n",
       "      <td>507.695122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>performance_type</th>\n",
       "      <td>384</td>\n",
       "      <td>84</td>\n",
       "      <td>496.423028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brother_agentType</th>\n",
       "      <td>407</td>\n",
       "      <td>92</td>\n",
       "      <td>489.131186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>town_locationSetting</th>\n",
       "      <td>553</td>\n",
       "      <td>131</td>\n",
       "      <td>469.158442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male adult, other_agentType</th>\n",
       "      <td>627</td>\n",
       "      <td>149</td>\n",
       "      <td>451.213525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>royalty, female_agentType</th>\n",
       "      <td>354</td>\n",
       "      <td>87</td>\n",
       "      <td>445.217652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_note</th>\n",
       "      <td>192</td>\n",
       "      <td>31</td>\n",
       "      <td>439.602796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mother_agentType</th>\n",
       "      <td>567</td>\n",
       "      <td>143</td>\n",
       "      <td>431.339847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clergyman or clergy_agentType</th>\n",
       "      <td>503</td>\n",
       "      <td>130</td>\n",
       "      <td>430.593478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Term_freq  Doc_freq       tf_idf\n",
       "Response                                                       \n",
       "lover, male, named_agentType         776        75  1091.131263\n",
       "hospital_locationStructure           617        71   901.378524\n",
       "sovereign, male_agentType            655        79   886.959898\n",
       "nobleman, named_agentType            853       122   784.388141\n",
       "husband_agentType                   1245       165   768.961337\n",
       "royalty, male_agentType              753       111   763.583340\n",
       "conversation_type                   1118       171   650.588288\n",
       "nursing, professional_type           281        33   625.808789\n",
       "famous man_agentType                 712       129   615.006161\n",
       "officer, military_agentType          540        98   614.853517\n",
       "theater_locationStructure            296        55   508.010567\n",
       "love affair_type                     400        86   507.695122\n",
       "performance_type                     384        84   496.423028\n",
       "brother_agentType                    407        92   489.131186\n",
       "town_locationSetting                 553       131   469.158442\n",
       "male adult, other_agentType          627       149   451.213525\n",
       "royalty, female_agentType            354        87   445.217652\n",
       " _note                               192        31   439.602796\n",
       "mother_agentType                     567       143   431.339847\n",
       "clergyman or clergy_agentType        503       130   430.593478"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_by_counts = pd.concat([term_freq,doc_count],axis = 1)\n",
    "\n",
    "group_by_counts.columns = ['Term_freq','Doc_freq']\n",
    "group_by_counts['tf_idf'] = pd.DataFrame(group_by_counts['Term_freq'] * np.log(total_docs/group_by_counts['Doc_freq']) )\n",
    "\n",
    "group_by_counts.sort_values(['tf_idf'],ascending=False)[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bio_response = pd.DataFrame(bess_reponse.groupby(['Response'])['Bio_col_para_id'].apply(lambda x: len(np.unique(x))))\n",
    "# bio_response.sort_values(['Bio_col_para_id'],ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Creating the Respone Variable for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Select the event for building the model\n",
    "reponse_required = 'royalty, male_agentType'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "reponse_required_to_merge = bess_reponse[bess_reponse.Response == reponse_required]\n",
    "\n",
    "##### Merging the features and the response dataset\n",
    "text_data_merge = pd.merge(text_data_sentence, reponse_required_to_merge.drop_duplicates(),\\\n",
    "                     how = 'left', left_on=['CollectionID','BiographyID','ParagraphNo'],\n",
    "                         right_on=['collectionID','biographyID','para no'])\n",
    "\n",
    "\n",
    "########## Final Data Frame #############\n",
    "final_data_frame = text_data_merge.loc[:,['ParagraphText','Response']]\n",
    "\n",
    "final_data_frame['Response_binary'] = np.where(final_data_frame.Response.isnull(),0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Distribution of the Response variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16010\n",
       "1      627\n",
       "Name: Response_binary, dtype: int64"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data_frame.Response_binary.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Prepocessing the Paragraph Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.1 StopWord collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting stop words - High Frequency and Low Frequency word list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "tokenized_para = final_data_frame.ParagraphText.apply(word_tokenize)\n",
    "\n",
    "all_sent = [words for each_sent in tokenized_para for words in each_sent]\n",
    "\n",
    "count_dict = Counter(all_sent)\n",
    "\n",
    "high_freq_words = [word for (word,count) in count_dict.most_common(500)]\n",
    "\n",
    "less_freq_words = []\n",
    "threshold = 5\n",
    "\n",
    "for k,v in count_dict.items():\n",
    "    \n",
    "    if v < threshold:\n",
    "        less_freq_words.append(k)\n",
    "\n",
    "        \n",
    "######### List of all stop words ##########\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(high_freq_words)\n",
    "stop_words.extend(less_freq_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Creating Training and Test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(final_data_frame.ParagraphText ,final_data_frame.Response_binary,\n",
    "                                                    test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Splitting the dataset into two categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bin_1 = X_train[y_train == 1]\n",
    "data_bin_0 = X_train[y_train == 0]\n",
    "\n",
    "dict_bin_1_tokens = word_tokenize(' '.join(data_bin_1))\n",
    "dict_bin_0_tokens = word_tokenize(' '.join(data_bin_0))\n",
    "\n",
    "### Creating a dictionary for Counter 1\n",
    "df_bin_1_tokens = pd.DataFrame(dict_bin_1_tokens)\n",
    "dictionary_bin_1 = Counter(df_bin_1_tokens[~df_bin_1_tokens[0].isin(stop_words)][0].values)\n",
    "\n",
    "### Creating a dictionary for Counter 1\n",
    "df_bin_0_tokens = pd.DataFrame(dict_bin_0_tokens)\n",
    "dictionary_bin_0 = Counter(df_bin_0_tokens[(~(df_bin_0_tokens[0].isin(stop_words)))][0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Creating a dataframe of probabilites ######################\n",
    "vocab_size = sum(dictionary_bin_1.values())\n",
    "for k,v in dictionary_bin_1.items():\n",
    "    dictionary_bin_1[k] = v/vocab_size\n",
    "    \n",
    "vocab_size_0 = sum(dictionary_bin_0.values())\n",
    "for k_0,v_0 in dictionary_bin_0.items():\n",
    "    dictionary_bin_0[k_0] = v_0/vocab_size_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Creating a dictionary of all the words in each of the binary category 1 and 0 ##############\n",
    "\n",
    "bin_1_value = X_test.apply(lambda x: \\\n",
    "                           sum([dictionary_bin_1[each] for each in word_tokenize(x)]))\n",
    "\n",
    "bin_0_value = X_test.apply(lambda x: \\\n",
    "                           sum([dictionary_bin_0[each] for each in word_tokenize(x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame([bin_1_value,bin_0_value]).T\n",
    "df_result.columns = ['bin_1_value','bin_0_value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Language Model Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_1_only = [each for each in dictionary_bin_1 if each not in dictionary_bin_0.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size:  16788\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocab Size: \",len(keys_1_only) + len(dictionary_bin_0.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1204"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_result.bin_0_value < df_result.bin_1_value).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Accuracy and Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100 * (df_result.bin_0_value < df_result.bin_1_value).sum()/len(df_result.bin_1_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3194\n",
       "1     134\n",
       "Name: Response_binary, dtype: int64"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size:  16788\n",
      "Accuracy:  0.6706730769230769\n",
      "F1 score:  0.18086696562032883\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "preds = (df_result.bin_0_value < df_result.bin_1_value).astype('int')\n",
    "\n",
    "keys_1_only = [each for each in dictionary_bin_1 if each not in dictionary_bin_0.keys()]\n",
    "\n",
    "print(\"Vocab Size: \", len(keys_1_only) + len(dictionary_bin_0.keys()))\n",
    "print(\"Accuracy: \",(preds == y_test).sum()/len(y_test))\n",
    "print(\"F1 score: \",f1_score(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2111, 1083],\n",
       "       [  13,  121]], dtype=int64)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin_1_value</th>\n",
       "      <th>bin_0_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5704</th>\n",
       "      <td>0.034752</td>\n",
       "      <td>0.032477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7959</th>\n",
       "      <td>0.009278</td>\n",
       "      <td>0.008249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13407</th>\n",
       "      <td>0.002149</td>\n",
       "      <td>0.002135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4384</th>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.000227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13743</th>\n",
       "      <td>0.003093</td>\n",
       "      <td>0.001797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bin_1_value  bin_0_value\n",
       "5704      0.034752     0.032477\n",
       "7959      0.009278     0.008249\n",
       "13407     0.002149     0.002135\n",
       "4384      0.000839     0.000227\n",
       "13743     0.003093     0.001797"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result[df_result.bin_0_value < df_result.bin_1_value].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Considering the words with higher probability in 1 and 0\n",
    "\n",
    "primary_words = []\n",
    "\n",
    "for each in dictionary_bin_0.keys():\n",
    "    if dictionary_bin_0[each] < dictionary_bin_1[each]:\n",
    "        primary_words.append(each)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Significant Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ton',\n",
       " 'southern',\n",
       " 'gentle-',\n",
       " 'union',\n",
       " 'occurred',\n",
       " 'sublime',\n",
       " 'hunt',\n",
       " 'sovereign',\n",
       " 'difference']"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primary_words[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Modification - Including the words that are present for the binary class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bin_1 = X_train[y_train == 1]\n",
    "data_bin_0 = X_train[y_train == 0]\n",
    "\n",
    "dict_bin_1_tokens = word_tokenize(' '.join(data_bin_1))\n",
    "dict_bin_0_tokens = word_tokenize(' '.join(data_bin_0))\n",
    "\n",
    "### Creating a dictionary for Counter 1\n",
    "df_bin_1_tokens = pd.DataFrame(dict_bin_1_tokens)\n",
    "dictionary_bin_1 = Counter(df_bin_1_tokens[~df_bin_1_tokens[0].isin(stop_words)][0].values)\n",
    "\n",
    "### Creating a dictionary for Counter 1\n",
    "df_bin_0_tokens = pd.DataFrame(dict_bin_0_tokens)\n",
    "dictionary_bin_0 = Counter(df_bin_0_tokens[(~(df_bin_0_tokens[0].isin(stop_words))) & \\\n",
    "                                           (df_bin_0_tokens[0].isin(dict_bin_1_tokens))][0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Creating a dataframe of probabilites ######################\n",
    "\n",
    "vocab_size = sum(dictionary_bin_1.values())\n",
    "for k,v in dictionary_bin_1.items():\n",
    "    dictionary_bin_1[k] = v/vocab_size\n",
    "    \n",
    "vocab_size_0 = sum(dictionary_bin_0.values())\n",
    "for k_0,v_0 in dictionary_bin_0.items():\n",
    "    dictionary_bin_0[k_0] = v_0/vocab_size_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Creating a dictionary of all the words in each of the binary category 1 and 0 ##############\n",
    "\n",
    "bin_1_value = X_test.apply(lambda x: \\\n",
    "                           sum([dictionary_bin_1[each] for each in word_tokenize(x)]))\n",
    "\n",
    "bin_0_value = X_test.apply(lambda x: \\\n",
    "                           sum([dictionary_bin_0[each] for each in word_tokenize(x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame([bin_1_value,bin_0_value]).T\n",
    "df_result.columns = ['bin_1_value','bin_0_value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Language Model Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(df_result.bin_0_value < df_result.bin_1_value).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3194\n",
       "1     134\n",
       "Name: Response_binary, dtype: int64"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size 7306\n",
      "Accuracy:  0.8671875\n",
      "F1 score:  0.2754098360655738\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "preds = (df_result.bin_0_value < df_result.bin_1_value).astype('int')\n",
    "\n",
    "### Evaluation ###\n",
    "print(\"Vocab Size\", len(dictionary_bin_1.keys()))\n",
    "print(\"Accuracy: \",(preds == y_test).sum()/len(y_test))\n",
    "print(\"F1 score: \",f1_score(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2802,  392],\n",
       "       [  50,   84]], dtype=int64)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin_1_value</th>\n",
       "      <th>bin_0_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16621</th>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4384</th>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.000270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13743</th>\n",
       "      <td>0.003093</td>\n",
       "      <td>0.002428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5354</th>\n",
       "      <td>0.009435</td>\n",
       "      <td>0.009319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11565</th>\n",
       "      <td>0.008491</td>\n",
       "      <td>0.008134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bin_1_value  bin_0_value\n",
       "16621     0.000105     0.000078\n",
       "4384      0.000839     0.000270\n",
       "13743     0.003093     0.002428\n",
       "5354      0.009435     0.009319\n",
       "11565     0.008491     0.008134"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result[df_result.bin_0_value < df_result.bin_1_value].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Considering the words with higher probability in 1 and 0\n",
    "\n",
    "primary_words = []\n",
    "\n",
    "for each in dictionary_bin_0.keys():\n",
    "    if dictionary_bin_0[each] < dictionary_bin_1[each]:\n",
    "        primary_words.append(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['plan',\n",
       " 'union',\n",
       " 'empress',\n",
       " 'sublime',\n",
       " 'plot',\n",
       " 'hunt',\n",
       " 'sovereign',\n",
       " 'mistress',\n",
       " 'Besides']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primary_words[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
