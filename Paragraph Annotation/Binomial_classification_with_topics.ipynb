{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reading the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/Users/user/Documents/github/CBW/data/text_data_sentence_wtopics.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CollectionID</th>\n",
       "      <th>BiographyID</th>\n",
       "      <th>ParagraphNo</th>\n",
       "      <th>ParagraphText</th>\n",
       "      <th>Topic 0</th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "      <th>Topic 3</th>\n",
       "      <th>Topic 4</th>\n",
       "      <th>Topic 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>a001</td>\n",
       "      <td>bio04</td>\n",
       "      <td>1</td>\n",
       "      <td>A FRENCH philosopher, moralizing on the great ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.259191</td>\n",
       "      <td>0.456633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.270889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>a001</td>\n",
       "      <td>bio04</td>\n",
       "      <td>2</td>\n",
       "      <td>Cleopatra was joint heir to the throne of Egyp...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.982856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>a001</td>\n",
       "      <td>bio04</td>\n",
       "      <td>3</td>\n",
       "      <td>Cleopatra might have responded with a brillian...</td>\n",
       "      <td>0.237276</td>\n",
       "      <td>0.620166</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>a001</td>\n",
       "      <td>bio04</td>\n",
       "      <td>4</td>\n",
       "      <td>Caesar was then above fifty years of age. His ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.747046</td>\n",
       "      <td>0.245938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>a001</td>\n",
       "      <td>bio04</td>\n",
       "      <td>5</td>\n",
       "      <td>For three years Cleopatra reigned with little ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.979924</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012819</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 CollectionID BiographyID  ParagraphNo  \\\n",
       "0           0         a001       bio04            1   \n",
       "1           1         a001       bio04            2   \n",
       "2           2         a001       bio04            3   \n",
       "3           3         a001       bio04            4   \n",
       "4           4         a001       bio04            5   \n",
       "\n",
       "                                       ParagraphText   Topic 0   Topic 1  \\\n",
       "0  A FRENCH philosopher, moralizing on the great ...  0.000000  0.259191   \n",
       "1  Cleopatra was joint heir to the throne of Egyp...  0.000000  0.982856   \n",
       "2  Cleopatra might have responded with a brillian...  0.237276  0.620166   \n",
       "3  Caesar was then above fifty years of age. His ...  0.000000  0.747046   \n",
       "4  For three years Cleopatra reigned with little ...  0.000000  0.979924   \n",
       "\n",
       "    Topic 2  Topic 3   Topic 4   Topic 5  \n",
       "0  0.456633      0.0  0.000000  0.270889  \n",
       "1  0.000000      0.0  0.000000  0.000000  \n",
       "2  0.000000      0.0  0.000000  0.136395  \n",
       "3  0.245938      0.0  0.000000  0.000000  \n",
       "4  0.000000      0.0  0.012819  0.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data_sentence = pd.read_csv(path, encoding='ISO-8859-1')\n",
    "text_data_sentence.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Reading the text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2='/Users/user/Documents/github/CBW/data/text_features.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (11,12,15,16,22,23,24,29,30,31,32,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "text_features = pd.read_csv(path2, encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CollectionID</th>\n",
       "      <th>BiographyID</th>\n",
       "      <th>ParagraphNo</th>\n",
       "      <th>sadness</th>\n",
       "      <th>joy</th>\n",
       "      <th>fear</th>\n",
       "      <th>disgust</th>\n",
       "      <th>anger</th>\n",
       "      <th>score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>...</th>\n",
       "      <th>Number</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Person</th>\n",
       "      <th>PrintMedia</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Sport</th>\n",
       "      <th>SportingEvent</th>\n",
       "      <th>TelevisionShow</th>\n",
       "      <th>Time</th>\n",
       "      <th>Vehicle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a001</td>\n",
       "      <td>bio04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.255896</td>\n",
       "      <td>0.558011</td>\n",
       "      <td>0.101166</td>\n",
       "      <td>0.111615</td>\n",
       "      <td>0.054668</td>\n",
       "      <td>0.290669</td>\n",
       "      <td>positive</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a001</td>\n",
       "      <td>bio04</td>\n",
       "      <td>2</td>\n",
       "      <td>0.171629</td>\n",
       "      <td>0.257088</td>\n",
       "      <td>0.173474</td>\n",
       "      <td>0.098726</td>\n",
       "      <td>0.267978</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Roman senate</td>\n",
       "      <td>Cleopatra, Julius Caesar, Pompey, Ptolemy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  CollectionID BiographyID  ParagraphNo   sadness       joy      fear  \\\n",
       "0         a001       bio04            1  0.255896  0.558011  0.101166   \n",
       "1         a001       bio04            2  0.171629  0.257088  0.173474   \n",
       "\n",
       "    disgust     anger     score sentiment   ...   Number  Organization  \\\n",
       "0  0.111615  0.054668  0.290669  positive   ...      NaN           NaN   \n",
       "1  0.098726  0.267978  0.000000   neutral   ...      NaN  Roman senate   \n",
       "\n",
       "                                      Person PrintMedia Quantity Sport  \\\n",
       "0                                  Cleopatra        NaN      NaN   NaN   \n",
       "1  Cleopatra, Julius Caesar, Pompey, Ptolemy        NaN      NaN   NaN   \n",
       "\n",
       "  SportingEvent TelevisionShow Time Vehicle  \n",
       "0           NaN            NaN  NaN     NaN  \n",
       "1           NaN            NaN  NaN     NaN  \n",
       "\n",
       "[2 rows x 34 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_features.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Reading the Response file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path3 = '/Users/user/Documents/github/CBW/data/CBW_Bess_tags_final2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bess_tags = pd.read_csv(path3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Event</th>\n",
       "      <th>Type</th>\n",
       "      <th>para no</th>\n",
       "      <th>URI</th>\n",
       "      <th>author</th>\n",
       "      <th>biographyID</th>\n",
       "      <th>collectionID</th>\n",
       "      <th>personaName</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>after</td>\n",
       "      <td>name</td>\n",
       "      <td>stageOfLife</td>\n",
       "      <td>1.0</td>\n",
       "      <td>a001.bio04.bess.xml</td>\n",
       "      <td>Willis John Abbot</td>\n",
       "      <td>bio04</td>\n",
       "      <td>a001</td>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>Cleopatra (B.C. 69-30): The World's Most Famou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>culmination</td>\n",
       "      <td>name</td>\n",
       "      <td>stageOfLife</td>\n",
       "      <td>1.0</td>\n",
       "      <td>a001.bio04.bess.xml</td>\n",
       "      <td>Willis John Abbot</td>\n",
       "      <td>bio04</td>\n",
       "      <td>a001</td>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>Cleopatra (B.C. 69-30): The World's Most Famou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>middle</td>\n",
       "      <td>name</td>\n",
       "      <td>stageOfLife</td>\n",
       "      <td>2.0</td>\n",
       "      <td>a001.bio04.bess.xml</td>\n",
       "      <td>Willis John Abbot</td>\n",
       "      <td>bio04</td>\n",
       "      <td>a001</td>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>Cleopatra (B.C. 69-30): The World's Most Famou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>middle</td>\n",
       "      <td>name</td>\n",
       "      <td>stageOfLife</td>\n",
       "      <td>3.0</td>\n",
       "      <td>a001.bio04.bess.xml</td>\n",
       "      <td>Willis John Abbot</td>\n",
       "      <td>bio04</td>\n",
       "      <td>a001</td>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>Cleopatra (B.C. 69-30): The World's Most Famou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>middle</td>\n",
       "      <td>name</td>\n",
       "      <td>stageOfLife</td>\n",
       "      <td>4.0</td>\n",
       "      <td>a001.bio04.bess.xml</td>\n",
       "      <td>Willis John Abbot</td>\n",
       "      <td>bio04</td>\n",
       "      <td>a001</td>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>Cleopatra (B.C. 69-30): The World's Most Famou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Content Event         Type  para no                  URI  \\\n",
       "0        after  name  stageOfLife      1.0  a001.bio04.bess.xml   \n",
       "1  culmination  name  stageOfLife      1.0  a001.bio04.bess.xml   \n",
       "2       middle  name  stageOfLife      2.0  a001.bio04.bess.xml   \n",
       "3       middle  name  stageOfLife      3.0  a001.bio04.bess.xml   \n",
       "4       middle  name  stageOfLife      4.0  a001.bio04.bess.xml   \n",
       "\n",
       "              author biographyID collectionID personaName  \\\n",
       "0  Willis John Abbot       bio04         a001   Cleopatra   \n",
       "1  Willis John Abbot       bio04         a001   Cleopatra   \n",
       "2  Willis John Abbot       bio04         a001   Cleopatra   \n",
       "3  Willis John Abbot       bio04         a001   Cleopatra   \n",
       "4  Willis John Abbot       bio04         a001   Cleopatra   \n",
       "\n",
       "                                               title  \n",
       "0  Cleopatra (B.C. 69-30): The World's Most Famou...  \n",
       "1  Cleopatra (B.C. 69-30): The World's Most Famou...  \n",
       "2  Cleopatra (B.C. 69-30): The World's Most Famou...  \n",
       "3  Cleopatra (B.C. 69-30): The World's Most Famou...  \n",
       "4  Cleopatra (B.C. 69-30): The World's Most Famou...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bess_tags.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preprocessing BESS Response file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bess_reponse = bess_tags.loc[:,['Content','Event','Type','para no','biographyID','collectionID']]\n",
    "bess_reponse= bess_reponse.fillna(' ')\n",
    "\n",
    "### Creating a new column for the response variable\n",
    "bess_reponse.loc[:,'Response'] = bess_reponse.loc[:,['Content','Event']].apply(lambda x: '_'.join(x),axis = 1)\n",
    "\n",
    "\n",
    "### Concatenating columns to create new columns\n",
    "bess_reponse['Bio_col_id'] = bess_reponse['biographyID'] +\"_\" + bess_reponse['collectionID']\n",
    "bess_reponse['Bio_col_para_id'] = bess_reponse['Bio_col_id'] +\"_\" + bess_reponse['para no'].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Selecting the top BESS reponses for events based on TF-IDF method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_count = pd.DataFrame(bess_reponse[bess_reponse.Type.isin(['Event'])].\\\n",
    "                         groupby(['Response'])['Bio_col_id'].apply(lambda x: len(np.unique(x))))\n",
    "\n",
    "term_freq = pd.DataFrame(bess_reponse[bess_reponse.Type.isin(['Event'])].\\\n",
    "                            groupby(['Response'])['Bio_col_id'].count())\n",
    "\n",
    "total_docs = len(bess_reponse['Bio_col_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2 Grouping by the term frequencies to get the top values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term_freq</th>\n",
       "      <th>Doc_freq</th>\n",
       "      <th>tf_idf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Response</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lover, male, named_agentType</th>\n",
       "      <td>776</td>\n",
       "      <td>75</td>\n",
       "      <td>1091.131263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hospital_locationStructure</th>\n",
       "      <td>617</td>\n",
       "      <td>71</td>\n",
       "      <td>901.378524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sovereign, male_agentType</th>\n",
       "      <td>655</td>\n",
       "      <td>79</td>\n",
       "      <td>886.959898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nobleman, named_agentType</th>\n",
       "      <td>853</td>\n",
       "      <td>122</td>\n",
       "      <td>784.388141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>husband_agentType</th>\n",
       "      <td>1245</td>\n",
       "      <td>165</td>\n",
       "      <td>768.961337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>royalty, male_agentType</th>\n",
       "      <td>753</td>\n",
       "      <td>111</td>\n",
       "      <td>763.583340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conversation_type</th>\n",
       "      <td>1118</td>\n",
       "      <td>171</td>\n",
       "      <td>650.588288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nursing, professional_type</th>\n",
       "      <td>281</td>\n",
       "      <td>33</td>\n",
       "      <td>625.808789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>famous man_agentType</th>\n",
       "      <td>712</td>\n",
       "      <td>129</td>\n",
       "      <td>615.006161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>officer, military_agentType</th>\n",
       "      <td>540</td>\n",
       "      <td>98</td>\n",
       "      <td>614.853517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Term_freq  Doc_freq       tf_idf\n",
       "Response                                                      \n",
       "lover, male, named_agentType        776        75  1091.131263\n",
       "hospital_locationStructure          617        71   901.378524\n",
       "sovereign, male_agentType           655        79   886.959898\n",
       "nobleman, named_agentType           853       122   784.388141\n",
       "husband_agentType                  1245       165   768.961337\n",
       "royalty, male_agentType             753       111   763.583340\n",
       "conversation_type                  1118       171   650.588288\n",
       "nursing, professional_type          281        33   625.808789\n",
       "famous man_agentType                712       129   615.006161\n",
       "officer, military_agentType         540        98   614.853517"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_by_counts = pd.concat([term_freq,doc_count],axis = 1)\n",
    "\n",
    "group_by_counts.columns = ['Term_freq','Doc_freq']\n",
    "group_by_counts['tf_idf'] = pd.DataFrame(group_by_counts['Term_freq'] * np.log(total_docs/group_by_counts['Doc_freq']) )\n",
    "\n",
    "group_by_counts.sort_values(['tf_idf'],ascending=False)[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Preparing Final Respone File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Getting a distribution of all the responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bio_col_para_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Response</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>middle_name</th>\n",
       "      <td>8459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>culmination_name</th>\n",
       "      <td>2695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beginning_name</th>\n",
       "      <td>2365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evaluation_type</th>\n",
       "      <td>2286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emphasis in typeface, punctuation_type</th>\n",
       "      <td>2140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>present tense_type</th>\n",
       "      <td>1645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quotation, agent's speech, unique_type</th>\n",
       "      <td>1606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description of agent or identified set of agents_type</th>\n",
       "      <td>1535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direct address, use of we_type</th>\n",
       "      <td>1481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city_locationSetting</th>\n",
       "      <td>1180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Bio_col_para_id\n",
       "Response                                                           \n",
       "middle_name                                                    8459\n",
       "culmination_name                                               2695\n",
       "beginning_name                                                 2365\n",
       "evaluation_type                                                2286\n",
       "emphasis in typeface, punctuation_type                         2140\n",
       "present tense_type                                             1645\n",
       "quotation, agent's speech, unique_type                         1606\n",
       "description of agent or identified set of agent...             1535\n",
       "direct address, use of we_type                                 1481\n",
       "city_locationSetting                                           1180"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bio_response = pd.DataFrame(bess_reponse.groupby(['Response'])['Bio_col_para_id'].apply(lambda x: len(np.unique(x))))\n",
    "bio_response.sort_values(['Bio_col_para_id'],ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Selecting the response to Analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reponse_required = 'lover, male, named_agentType'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data_sentence.BiographyID.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reponse_required_to_merge['para no']=reponse_required_to_merge['para no'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reponse_required_to_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_data_sentence['CollectionID']=text_data_sentence['CollectionID'].astype(str)\n",
    "#text_data_sentence['BiographyID']=text_data_sentence['BiographyID'].astype(str)\n",
    "#text_data_sentence['ParagraphNo']=text_data_sentence['ParagraphNo'].astype(str)\n",
    "\n",
    "\n",
    "#reponse_required_to_merge['collectionID']=reponse_required_to_merge['collectionID'].astype(str)\n",
    "#reponse_required_to_merge['biographyID']=reponse_required_to_merge['biographyID'].astype(str)\n",
    "#reponse_required_to_merge['para no']=reponse_required_to_merge['para no'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParagraphText</th>\n",
       "      <th>Response</th>\n",
       "      <th>Response_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A FRENCH philosopher, moralizing on the great ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cleopatra was joint heir to the throne of Egyp...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cleopatra might have responded with a brillian...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Caesar was then above fifty years of age. His ...</td>\n",
       "      <td>lover, male, named_agentType</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>For three years Cleopatra reigned with little ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       ParagraphText  \\\n",
       "0  A FRENCH philosopher, moralizing on the great ...   \n",
       "1  Cleopatra was joint heir to the throne of Egyp...   \n",
       "2  Cleopatra might have responded with a brillian...   \n",
       "3  Caesar was then above fifty years of age. His ...   \n",
       "4  For three years Cleopatra reigned with little ...   \n",
       "\n",
       "                       Response  Response_binary  \n",
       "0                           NaN                0  \n",
       "1                           NaN                0  \n",
       "2                           NaN                0  \n",
       "3  lover, male, named_agentType                1  \n",
       "4                           NaN                0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reponse_required_to_merge = bess_reponse[bess_reponse.Response == reponse_required]\n",
    "text_data_sentence.ParagraphNo = text_data_sentence.ParagraphNo.astype('int')\n",
    "reponse_required_to_merge['para no'] = reponse_required_to_merge['para no'].astype('int')\n",
    "\n",
    "### Merging the response with the text data file\n",
    "text_data_merge = pd.merge(text_data_sentence, reponse_required_to_merge.drop_duplicates(),\\\n",
    "                     how = 'left', left_on=['CollectionID','BiographyID','ParagraphNo'],\n",
    "                         right_on=['collectionID','biographyID','para no'])\n",
    "\n",
    "final_data_frame = text_data_merge.loc[:,['ParagraphText','Response']]\n",
    "final_data_frame['Response_binary'] = np.where(final_data_frame.Response.isnull(),0,1)\n",
    "final_data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16054\n",
       "1      583\n",
       "Name: Response_binary, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data_frame.Response_binary.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Text Data - Preprocessing on the Final Response file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Getting stop words\n",
    "#### High Frequency and Low Frequency word list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_para = final_data_frame.ParagraphText.apply(word_tokenize)\n",
    "\n",
    "all_sent = [words for each_sent in tokenized_para for words in each_sent]\n",
    "\n",
    "count_dict = Counter(all_sent)\n",
    "high_freq_words = [word for (word,count) in count_dict.most_common(500)]\n",
    "\n",
    "#### Getting Low Frequency words - based on a threshold\n",
    "less_freq_words = []\n",
    "threshold = 5\n",
    "\n",
    "for k,v in count_dict.items():\n",
    "    \n",
    "    if v < threshold:\n",
    "        less_freq_words.append(k)\n",
    "        \n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(high_freq_words)\n",
    "stop_words.extend(less_freq_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_model = CountVectorizer(ngram_range= (1,2),stop_words=stop_words)\n",
    "Para_text_bow = bow_model.fit_transform(final_data_frame.ParagraphText)\n",
    "\n",
    "features = bow_model.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CollectionID</th>\n",
       "      <th>BiographyID</th>\n",
       "      <th>ParagraphNo</th>\n",
       "      <th>ParagraphText</th>\n",
       "      <th>Topic 0</th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "      <th>Topic 3</th>\n",
       "      <th>Topic 4</th>\n",
       "      <th>Topic 5</th>\n",
       "      <th>Content</th>\n",
       "      <th>Event</th>\n",
       "      <th>Type</th>\n",
       "      <th>para no</th>\n",
       "      <th>biographyID</th>\n",
       "      <th>collectionID</th>\n",
       "      <th>Response</th>\n",
       "      <th>Bio_col_id</th>\n",
       "      <th>Bio_col_para_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>a001</td>\n",
       "      <td>bio04</td>\n",
       "      <td>1</td>\n",
       "      <td>A FRENCH philosopher, moralizing on the great ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.259191</td>\n",
       "      <td>0.456633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.270889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>a001</td>\n",
       "      <td>bio04</td>\n",
       "      <td>2</td>\n",
       "      <td>Cleopatra was joint heir to the throne of Egyp...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.982856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>a001</td>\n",
       "      <td>bio04</td>\n",
       "      <td>3</td>\n",
       "      <td>Cleopatra might have responded with a brillian...</td>\n",
       "      <td>0.237276</td>\n",
       "      <td>0.620166</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136395</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>a001</td>\n",
       "      <td>bio04</td>\n",
       "      <td>4</td>\n",
       "      <td>Caesar was then above fifty years of age. His ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.747046</td>\n",
       "      <td>0.245938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>lover, male, named</td>\n",
       "      <td>agentType</td>\n",
       "      <td>Event</td>\n",
       "      <td>4.0</td>\n",
       "      <td>bio04</td>\n",
       "      <td>a001</td>\n",
       "      <td>lover, male, named_agentType</td>\n",
       "      <td>bio04_a001</td>\n",
       "      <td>bio04_a001_4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>a001</td>\n",
       "      <td>bio04</td>\n",
       "      <td>5</td>\n",
       "      <td>For three years Cleopatra reigned with little ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.979924</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 CollectionID BiographyID  ParagraphNo  \\\n",
       "0           0         a001       bio04            1   \n",
       "1           1         a001       bio04            2   \n",
       "2           2         a001       bio04            3   \n",
       "3           3         a001       bio04            4   \n",
       "4           4         a001       bio04            5   \n",
       "\n",
       "                                       ParagraphText   Topic 0   Topic 1  \\\n",
       "0  A FRENCH philosopher, moralizing on the great ...  0.000000  0.259191   \n",
       "1  Cleopatra was joint heir to the throne of Egyp...  0.000000  0.982856   \n",
       "2  Cleopatra might have responded with a brillian...  0.237276  0.620166   \n",
       "3  Caesar was then above fifty years of age. His ...  0.000000  0.747046   \n",
       "4  For three years Cleopatra reigned with little ...  0.000000  0.979924   \n",
       "\n",
       "    Topic 2  Topic 3   Topic 4   Topic 5             Content      Event  \\\n",
       "0  0.456633      0.0  0.000000  0.270889                 NaN        NaN   \n",
       "1  0.000000      0.0  0.000000  0.000000                 NaN        NaN   \n",
       "2  0.000000      0.0  0.000000  0.136395                 NaN        NaN   \n",
       "3  0.245938      0.0  0.000000  0.000000  lover, male, named  agentType   \n",
       "4  0.000000      0.0  0.012819  0.000000                 NaN        NaN   \n",
       "\n",
       "    Type  para no biographyID collectionID                      Response  \\\n",
       "0    NaN      NaN         NaN          NaN                           NaN   \n",
       "1    NaN      NaN         NaN          NaN                           NaN   \n",
       "2    NaN      NaN         NaN          NaN                           NaN   \n",
       "3  Event      4.0       bio04         a001  lover, male, named_agentType   \n",
       "4    NaN      NaN         NaN          NaN                           NaN   \n",
       "\n",
       "   Bio_col_id Bio_col_para_id  \n",
       "0         NaN             NaN  \n",
       "1         NaN             NaN  \n",
       "2         NaN             NaN  \n",
       "3  bio04_a001  bio04_a001_4.0  \n",
       "4         NaN             NaN  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16637, 469815)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 0</th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "      <th>Topic 3</th>\n",
       "      <th>Topic 4</th>\n",
       "      <th>Topic 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.259191</td>\n",
       "      <td>0.456633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.270889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.982856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.237276</td>\n",
       "      <td>0.620166</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.747046</td>\n",
       "      <td>0.245938</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.979924</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012819</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.169664</td>\n",
       "      <td>0.576307</td>\n",
       "      <td>0.158173</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317665</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.655474</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.535851</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.169375</td>\n",
       "      <td>0.286884</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.262566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.719705</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.276829</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.698197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.011192</td>\n",
       "      <td>0.943881</td>\n",
       "      <td>0.011196</td>\n",
       "      <td>0.011321</td>\n",
       "      <td>0.011233</td>\n",
       "      <td>0.011177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.965033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.083650</td>\n",
       "      <td>0.084304</td>\n",
       "      <td>0.084136</td>\n",
       "      <td>0.083346</td>\n",
       "      <td>0.083815</td>\n",
       "      <td>0.580749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100959</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.851440</td>\n",
       "      <td>0.020965</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.024084</td>\n",
       "      <td>0.023959</td>\n",
       "      <td>0.023971</td>\n",
       "      <td>0.024056</td>\n",
       "      <td>0.024036</td>\n",
       "      <td>0.879895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.964940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.293815</td>\n",
       "      <td>0.122348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.573517</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.605415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.357128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.643129</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.345459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.365351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.604030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.165485</td>\n",
       "      <td>0.477670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.346114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.964887</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.353918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.630039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.983810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500067</td>\n",
       "      <td>0.476760</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.070701</td>\n",
       "      <td>0.320761</td>\n",
       "      <td>0.275759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.328404</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.424018</td>\n",
       "      <td>0.245311</td>\n",
       "      <td>0.313229</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.975905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.225108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.737408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125984</td>\n",
       "      <td>0.860534</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16607</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.980927</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16608</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.657091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.328623</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16609</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.983889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16610</th>\n",
       "      <td>0.024052</td>\n",
       "      <td>0.620112</td>\n",
       "      <td>0.283656</td>\n",
       "      <td>0.024056</td>\n",
       "      <td>0.023973</td>\n",
       "      <td>0.024151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16611</th>\n",
       "      <td>0.016779</td>\n",
       "      <td>0.916149</td>\n",
       "      <td>0.016717</td>\n",
       "      <td>0.016711</td>\n",
       "      <td>0.016756</td>\n",
       "      <td>0.016887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16612</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.976056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16613</th>\n",
       "      <td>0.033543</td>\n",
       "      <td>0.832099</td>\n",
       "      <td>0.033510</td>\n",
       "      <td>0.033521</td>\n",
       "      <td>0.033734</td>\n",
       "      <td>0.033593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16614</th>\n",
       "      <td>0.083936</td>\n",
       "      <td>0.083983</td>\n",
       "      <td>0.083785</td>\n",
       "      <td>0.083969</td>\n",
       "      <td>0.580399</td>\n",
       "      <td>0.083927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16615</th>\n",
       "      <td>0.016795</td>\n",
       "      <td>0.655289</td>\n",
       "      <td>0.016844</td>\n",
       "      <td>0.277481</td>\n",
       "      <td>0.016774</td>\n",
       "      <td>0.016819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16616</th>\n",
       "      <td>0.011177</td>\n",
       "      <td>0.944114</td>\n",
       "      <td>0.011155</td>\n",
       "      <td>0.011173</td>\n",
       "      <td>0.011194</td>\n",
       "      <td>0.011187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16617</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.976053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16618</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.983864</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16619</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.965111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16620</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.965054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16621</th>\n",
       "      <td>0.083531</td>\n",
       "      <td>0.083809</td>\n",
       "      <td>0.083441</td>\n",
       "      <td>0.083475</td>\n",
       "      <td>0.582027</td>\n",
       "      <td>0.083717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16622</th>\n",
       "      <td>0.016695</td>\n",
       "      <td>0.916485</td>\n",
       "      <td>0.016688</td>\n",
       "      <td>0.016686</td>\n",
       "      <td>0.016738</td>\n",
       "      <td>0.016708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16623</th>\n",
       "      <td>0.027860</td>\n",
       "      <td>0.027955</td>\n",
       "      <td>0.027812</td>\n",
       "      <td>0.860530</td>\n",
       "      <td>0.027966</td>\n",
       "      <td>0.027877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16624</th>\n",
       "      <td>0.015325</td>\n",
       "      <td>0.923315</td>\n",
       "      <td>0.015294</td>\n",
       "      <td>0.015356</td>\n",
       "      <td>0.015401</td>\n",
       "      <td>0.015309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16625</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.630643</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16626</th>\n",
       "      <td>0.010472</td>\n",
       "      <td>0.448304</td>\n",
       "      <td>0.509768</td>\n",
       "      <td>0.010466</td>\n",
       "      <td>0.010504</td>\n",
       "      <td>0.010486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16627</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.953398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16628</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.977889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16629</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.961978</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16630</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.967752</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16631</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.977331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16632</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.979513</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16633</th>\n",
       "      <td>0.028065</td>\n",
       "      <td>0.859992</td>\n",
       "      <td>0.027881</td>\n",
       "      <td>0.027990</td>\n",
       "      <td>0.028057</td>\n",
       "      <td>0.028015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16634</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.975323</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16635</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.959973</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16636</th>\n",
       "      <td>0.013988</td>\n",
       "      <td>0.441545</td>\n",
       "      <td>0.013941</td>\n",
       "      <td>0.013971</td>\n",
       "      <td>0.502550</td>\n",
       "      <td>0.014005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16637 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Topic 0   Topic 1   Topic 2   Topic 3   Topic 4   Topic 5\n",
       "0      0.000000  0.259191  0.456633  0.000000  0.000000  0.270889\n",
       "1      0.000000  0.982856  0.000000  0.000000  0.000000  0.000000\n",
       "2      0.237276  0.620166  0.000000  0.000000  0.000000  0.136395\n",
       "3      0.000000  0.747046  0.245938  0.000000  0.000000  0.000000\n",
       "4      0.000000  0.979924  0.000000  0.000000  0.012819  0.000000\n",
       "5      0.169664  0.576307  0.158173  0.000000  0.000000  0.088027\n",
       "6      0.000000  0.317665  0.000000  0.000000  0.655474  0.000000\n",
       "7      0.000000  0.535851  0.000000  0.169375  0.286884  0.000000\n",
       "8      0.000000  0.262566  0.000000  0.000000  0.719705  0.000000\n",
       "9      0.000000  0.000000  0.000000  0.276829  0.000000  0.698197\n",
       "10     0.011192  0.943881  0.011196  0.011321  0.011233  0.011177\n",
       "11     0.000000  0.000000  0.000000  0.000000  0.000000  0.965033\n",
       "12     0.083650  0.084304  0.084136  0.083346  0.083815  0.580749\n",
       "13     0.000000  0.100959  0.000000  0.851440  0.020965  0.000000\n",
       "14     0.024084  0.023959  0.023971  0.024056  0.024036  0.879895\n",
       "15     0.000000  0.964940  0.000000  0.000000  0.000000  0.000000\n",
       "16     0.293815  0.122348  0.000000  0.000000  0.573517  0.000000\n",
       "17     0.000000  0.605415  0.000000  0.000000  0.000000  0.357128\n",
       "18     0.000000  0.000000  0.643129  0.000000  0.000000  0.345459\n",
       "19     0.365351  0.000000  0.604030  0.000000  0.000000  0.000000\n",
       "20     0.000000  0.165485  0.477670  0.000000  0.000000  0.346114\n",
       "21     0.000000  0.000000  0.964887  0.000000  0.000000  0.000000\n",
       "22     0.353918  0.000000  0.630039  0.000000  0.000000  0.000000\n",
       "23     0.000000  0.000000  0.983810  0.000000  0.000000  0.000000\n",
       "24     0.000000  0.000000  0.500067  0.476760  0.000000  0.000000\n",
       "25     0.070701  0.320761  0.275759  0.000000  0.328404  0.000000\n",
       "26     0.000000  0.000000  0.424018  0.245311  0.313229  0.000000\n",
       "27     0.000000  0.000000  0.975905  0.000000  0.000000  0.000000\n",
       "28     0.000000  0.000000  0.000000  0.225108  0.000000  0.737408\n",
       "29     0.000000  0.125984  0.860534  0.000000  0.000000  0.000000\n",
       "...         ...       ...       ...       ...       ...       ...\n",
       "16607  0.000000  0.980927  0.000000  0.000000  0.000000  0.000000\n",
       "16608  0.000000  0.657091  0.000000  0.000000  0.328623  0.000000\n",
       "16609  0.000000  0.983889  0.000000  0.000000  0.000000  0.000000\n",
       "16610  0.024052  0.620112  0.283656  0.024056  0.023973  0.024151\n",
       "16611  0.016779  0.916149  0.016717  0.016711  0.016756  0.016887\n",
       "16612  0.000000  0.976056  0.000000  0.000000  0.000000  0.000000\n",
       "16613  0.033543  0.832099  0.033510  0.033521  0.033734  0.033593\n",
       "16614  0.083936  0.083983  0.083785  0.083969  0.580399  0.083927\n",
       "16615  0.016795  0.655289  0.016844  0.277481  0.016774  0.016819\n",
       "16616  0.011177  0.944114  0.011155  0.011173  0.011194  0.011187\n",
       "16617  0.000000  0.976053  0.000000  0.000000  0.000000  0.000000\n",
       "16618  0.000000  0.983864  0.000000  0.000000  0.000000  0.000000\n",
       "16619  0.000000  0.965111  0.000000  0.000000  0.000000  0.000000\n",
       "16620  0.000000  0.965054  0.000000  0.000000  0.000000  0.000000\n",
       "16621  0.083531  0.083809  0.083441  0.083475  0.582027  0.083717\n",
       "16622  0.016695  0.916485  0.016688  0.016686  0.016738  0.016708\n",
       "16623  0.027860  0.027955  0.027812  0.860530  0.027966  0.027877\n",
       "16624  0.015325  0.923315  0.015294  0.015356  0.015401  0.015309\n",
       "16625  0.000000  0.630643  0.000000  0.000000  0.000000  0.338823\n",
       "16626  0.010472  0.448304  0.509768  0.010466  0.010504  0.010486\n",
       "16627  0.000000  0.953398  0.000000  0.000000  0.000000  0.000000\n",
       "16628  0.000000  0.977889  0.000000  0.000000  0.000000  0.000000\n",
       "16629  0.000000  0.961978  0.000000  0.000000  0.000000  0.000000\n",
       "16630  0.000000  0.967752  0.000000  0.000000  0.000000  0.000000\n",
       "16631  0.000000  0.977331  0.000000  0.000000  0.000000  0.000000\n",
       "16632  0.000000  0.979513  0.000000  0.000000  0.000000  0.000000\n",
       "16633  0.028065  0.859992  0.027881  0.027990  0.028057  0.028015\n",
       "16634  0.000000  0.975323  0.000000  0.000000  0.000000  0.000000\n",
       "16635  0.000000  0.959973  0.000000  0.000000  0.000000  0.000000\n",
       "16636  0.013988  0.441545  0.013941  0.013971  0.502550  0.014005\n",
       "\n",
       "[16637 rows x 6 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data_merge.iloc[:,[5,6,7,8,9,10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Para_text_bow,\n",
    "X = sp.sparse.hstack((Para_text_bow,\n",
    "                     text_data_merge.iloc[:,[5,6,7,8,9,10]]),format='csr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Splitting data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X ,final_data_frame.Response_binary,\n",
    "                                                    test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = bow_model.get_feature_names()\n",
    "# features.extend(['Sentiment'])\n",
    "# features.extend(emotional_features.columns.values)\n",
    "# features.extend(text_data_spacy_features_codes.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn_model = KNeighborsClassifier(n_neighbors= 3, p = 1.5)\n",
    "rf_model = RandomForestClassifier(n_estimators= 50)\n",
    "lr_model = LogisticRegression(multi_class='multinomial')\n",
    "#rf_model = SVC(C = 10, kernel = 'poly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Reviewing the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4988\n",
       "1       4\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(rf_model.predict(X_test))[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Almost all the values are predicited as 1. Now looking at the confusion matrix, even all the predicted ones are not correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   3,    0, 4808],\n",
       "       [   1,    0,  180],\n",
       "       [   0,    0,    0]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "preds = pd.DataFrame([np.argmax(each) if each.sum() != 0 else 10 for each in rf_model.predict(X_test)])[0]\n",
    "\n",
    "confusion_matrix(y_test,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
