{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reading input datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Reading the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CollectionID</th>\n",
       "      <th>BiographyID</th>\n",
       "      <th>ParagraphNo</th>\n",
       "      <th>ParagraphText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a001</td>\n",
       "      <td>bio04</td>\n",
       "      <td>1</td>\n",
       "      <td>A FRENCH philosopher, moralizing on the great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a001</td>\n",
       "      <td>bio04</td>\n",
       "      <td>2</td>\n",
       "      <td>Cleopatra was joint heir to the throne of Egyp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a001</td>\n",
       "      <td>bio04</td>\n",
       "      <td>3</td>\n",
       "      <td>Cleopatra might have responded with a brillian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a001</td>\n",
       "      <td>bio04</td>\n",
       "      <td>4</td>\n",
       "      <td>Caesar was then above fifty years of age. His ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a001</td>\n",
       "      <td>bio04</td>\n",
       "      <td>5</td>\n",
       "      <td>For three years Cleopatra reigned with little ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CollectionID BiographyID  ParagraphNo  \\\n",
       "0         a001       bio04            1   \n",
       "1         a001       bio04            2   \n",
       "2         a001       bio04            3   \n",
       "3         a001       bio04            4   \n",
       "4         a001       bio04            5   \n",
       "\n",
       "                                       ParagraphText  \n",
       "0  A FRENCH philosopher, moralizing on the great ...  \n",
       "1  Cleopatra was joint heir to the throne of Egyp...  \n",
       "2  Cleopatra might have responded with a brillian...  \n",
       "3  Caesar was then above fifty years of age. His ...  \n",
       "4  For three years Cleopatra reigned with little ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data_sentence = pd.read_csv('./Files/textdatanew.csv', encoding='ISO-8859-1')\n",
    "text_data_sentence.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Reading the text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arvra\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (11,12,15,16,22,23,24,29,30,31,32,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CollectionID</th>\n",
       "      <th>BiographyID</th>\n",
       "      <th>ParagraphNo</th>\n",
       "      <th>sadness</th>\n",
       "      <th>joy</th>\n",
       "      <th>fear</th>\n",
       "      <th>disgust</th>\n",
       "      <th>anger</th>\n",
       "      <th>score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>...</th>\n",
       "      <th>Number</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Person</th>\n",
       "      <th>PrintMedia</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Sport</th>\n",
       "      <th>SportingEvent</th>\n",
       "      <th>TelevisionShow</th>\n",
       "      <th>Time</th>\n",
       "      <th>Vehicle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a001</td>\n",
       "      <td>bio04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.255896</td>\n",
       "      <td>0.558011</td>\n",
       "      <td>0.101166</td>\n",
       "      <td>0.111615</td>\n",
       "      <td>0.054668</td>\n",
       "      <td>0.290669</td>\n",
       "      <td>positive</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a001</td>\n",
       "      <td>bio04</td>\n",
       "      <td>2</td>\n",
       "      <td>0.171629</td>\n",
       "      <td>0.257088</td>\n",
       "      <td>0.173474</td>\n",
       "      <td>0.098726</td>\n",
       "      <td>0.267978</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Roman senate</td>\n",
       "      <td>Cleopatra, Julius Caesar, Pompey, Ptolemy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  CollectionID BiographyID  ParagraphNo   sadness       joy      fear  \\\n",
       "0         a001       bio04            1  0.255896  0.558011  0.101166   \n",
       "1         a001       bio04            2  0.171629  0.257088  0.173474   \n",
       "\n",
       "    disgust     anger     score sentiment   ...   Number  Organization  \\\n",
       "0  0.111615  0.054668  0.290669  positive   ...      NaN           NaN   \n",
       "1  0.098726  0.267978  0.000000   neutral   ...      NaN  Roman senate   \n",
       "\n",
       "                                      Person PrintMedia Quantity Sport  \\\n",
       "0                                  Cleopatra        NaN      NaN   NaN   \n",
       "1  Cleopatra, Julius Caesar, Pompey, Ptolemy        NaN      NaN   NaN   \n",
       "\n",
       "  SportingEvent TelevisionShow Time Vehicle  \n",
       "0           NaN            NaN  NaN     NaN  \n",
       "1           NaN            NaN  NaN     NaN  \n",
       "\n",
       "[2 rows x 34 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_features = pd.read_csv(\"text_features.csv\", encoding='ISO-8859-1')\n",
    "text_features.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Reading the Response file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Event</th>\n",
       "      <th>Type</th>\n",
       "      <th>para no</th>\n",
       "      <th>URI</th>\n",
       "      <th>author</th>\n",
       "      <th>biographyID</th>\n",
       "      <th>collectionID</th>\n",
       "      <th>personaName</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>after</td>\n",
       "      <td>name</td>\n",
       "      <td>stageOfLife</td>\n",
       "      <td>1.0</td>\n",
       "      <td>a001.bio04.bess.xml</td>\n",
       "      <td>Willis John Abbot</td>\n",
       "      <td>bio04</td>\n",
       "      <td>a001</td>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>Cleopatra (B.C. 69-30): The World's Most Famou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>culmination</td>\n",
       "      <td>name</td>\n",
       "      <td>stageOfLife</td>\n",
       "      <td>1.0</td>\n",
       "      <td>a001.bio04.bess.xml</td>\n",
       "      <td>Willis John Abbot</td>\n",
       "      <td>bio04</td>\n",
       "      <td>a001</td>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>Cleopatra (B.C. 69-30): The World's Most Famou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>middle</td>\n",
       "      <td>name</td>\n",
       "      <td>stageOfLife</td>\n",
       "      <td>2.0</td>\n",
       "      <td>a001.bio04.bess.xml</td>\n",
       "      <td>Willis John Abbot</td>\n",
       "      <td>bio04</td>\n",
       "      <td>a001</td>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>Cleopatra (B.C. 69-30): The World's Most Famou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>middle</td>\n",
       "      <td>name</td>\n",
       "      <td>stageOfLife</td>\n",
       "      <td>3.0</td>\n",
       "      <td>a001.bio04.bess.xml</td>\n",
       "      <td>Willis John Abbot</td>\n",
       "      <td>bio04</td>\n",
       "      <td>a001</td>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>Cleopatra (B.C. 69-30): The World's Most Famou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>middle</td>\n",
       "      <td>name</td>\n",
       "      <td>stageOfLife</td>\n",
       "      <td>4.0</td>\n",
       "      <td>a001.bio04.bess.xml</td>\n",
       "      <td>Willis John Abbot</td>\n",
       "      <td>bio04</td>\n",
       "      <td>a001</td>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>Cleopatra (B.C. 69-30): The World's Most Famou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Content Event         Type  para no                  URI  \\\n",
       "0        after  name  stageOfLife      1.0  a001.bio04.bess.xml   \n",
       "1  culmination  name  stageOfLife      1.0  a001.bio04.bess.xml   \n",
       "2       middle  name  stageOfLife      2.0  a001.bio04.bess.xml   \n",
       "3       middle  name  stageOfLife      3.0  a001.bio04.bess.xml   \n",
       "4       middle  name  stageOfLife      4.0  a001.bio04.bess.xml   \n",
       "\n",
       "              author biographyID collectionID personaName  \\\n",
       "0  Willis John Abbot       bio04         a001   Cleopatra   \n",
       "1  Willis John Abbot       bio04         a001   Cleopatra   \n",
       "2  Willis John Abbot       bio04         a001   Cleopatra   \n",
       "3  Willis John Abbot       bio04         a001   Cleopatra   \n",
       "4  Willis John Abbot       bio04         a001   Cleopatra   \n",
       "\n",
       "                                               title  \n",
       "0  Cleopatra (B.C. 69-30): The World's Most Famou...  \n",
       "1  Cleopatra (B.C. 69-30): The World's Most Famou...  \n",
       "2  Cleopatra (B.C. 69-30): The World's Most Famou...  \n",
       "3  Cleopatra (B.C. 69-30): The World's Most Famou...  \n",
       "4  Cleopatra (B.C. 69-30): The World's Most Famou...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bess_tags = pd.read_csv('CBW_Bess_tags_final2.csv')\n",
    "bess_tags.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Getting the top Event types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bess_reponse = bess_tags.loc[:,['Content','Event','Type','para no','biographyID','collectionID']]\n",
    "\n",
    "bess_reponse= bess_reponse.fillna(' ')\n",
    "\n",
    "bess_reponse.loc[:,'Response'] = bess_reponse.loc[:,['Content','Event']].apply(lambda x: '_'.join(x),axis = 1)\n",
    "\n",
    "bess_reponse['Bio_col_id'] = bess_reponse['biographyID'] +\"_\" + bess_reponse['collectionID']\n",
    "bess_reponse['Bio_col_para_id'] = bess_reponse['Bio_col_id'] +\"_\" + bess_reponse['para no'].astype('str')\n",
    "\n",
    "doc_count = pd.DataFrame(bess_reponse[bess_reponse.Type.isin(['Event'])].\\\n",
    "                         groupby(['Response'])['Bio_col_id'].apply(lambda x: len(np.unique(x))))\n",
    "\n",
    "#############################################################################\n",
    "##########TF - IDF Approach to get the top event types ######################\n",
    "#############################################################################\n",
    "\n",
    "term_freq = pd.DataFrame(bess_reponse[bess_reponse.Type.isin(['Event'])].\\\n",
    "                            groupby(['Response'])['Bio_col_id'].count())\n",
    "\n",
    "total_docs = len(bess_reponse['Bio_col_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term_freq</th>\n",
       "      <th>Doc_freq</th>\n",
       "      <th>tf_idf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Response</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lover, male, named_agentType</th>\n",
       "      <td>776</td>\n",
       "      <td>75</td>\n",
       "      <td>1091.131263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hospital_locationStructure</th>\n",
       "      <td>617</td>\n",
       "      <td>71</td>\n",
       "      <td>901.378524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sovereign, male_agentType</th>\n",
       "      <td>655</td>\n",
       "      <td>79</td>\n",
       "      <td>886.959898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nobleman, named_agentType</th>\n",
       "      <td>853</td>\n",
       "      <td>122</td>\n",
       "      <td>784.388141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>husband_agentType</th>\n",
       "      <td>1245</td>\n",
       "      <td>165</td>\n",
       "      <td>768.961337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>royalty, male_agentType</th>\n",
       "      <td>753</td>\n",
       "      <td>111</td>\n",
       "      <td>763.583340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conversation_type</th>\n",
       "      <td>1118</td>\n",
       "      <td>171</td>\n",
       "      <td>650.588288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nursing, professional_type</th>\n",
       "      <td>281</td>\n",
       "      <td>33</td>\n",
       "      <td>625.808789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>famous man_agentType</th>\n",
       "      <td>712</td>\n",
       "      <td>129</td>\n",
       "      <td>615.006161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>officer, military_agentType</th>\n",
       "      <td>540</td>\n",
       "      <td>98</td>\n",
       "      <td>614.853517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theater_locationStructure</th>\n",
       "      <td>296</td>\n",
       "      <td>55</td>\n",
       "      <td>508.010567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love affair_type</th>\n",
       "      <td>400</td>\n",
       "      <td>86</td>\n",
       "      <td>507.695122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>performance_type</th>\n",
       "      <td>384</td>\n",
       "      <td>84</td>\n",
       "      <td>496.423028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brother_agentType</th>\n",
       "      <td>407</td>\n",
       "      <td>92</td>\n",
       "      <td>489.131186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>town_locationSetting</th>\n",
       "      <td>553</td>\n",
       "      <td>131</td>\n",
       "      <td>469.158442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male adult, other_agentType</th>\n",
       "      <td>627</td>\n",
       "      <td>149</td>\n",
       "      <td>451.213525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>royalty, female_agentType</th>\n",
       "      <td>354</td>\n",
       "      <td>87</td>\n",
       "      <td>445.217652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_note</th>\n",
       "      <td>192</td>\n",
       "      <td>31</td>\n",
       "      <td>439.602796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mother_agentType</th>\n",
       "      <td>567</td>\n",
       "      <td>143</td>\n",
       "      <td>431.339847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clergyman or clergy_agentType</th>\n",
       "      <td>503</td>\n",
       "      <td>130</td>\n",
       "      <td>430.593478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Term_freq  Doc_freq       tf_idf\n",
       "Response                                                       \n",
       "lover, male, named_agentType         776        75  1091.131263\n",
       "hospital_locationStructure           617        71   901.378524\n",
       "sovereign, male_agentType            655        79   886.959898\n",
       "nobleman, named_agentType            853       122   784.388141\n",
       "husband_agentType                   1245       165   768.961337\n",
       "royalty, male_agentType              753       111   763.583340\n",
       "conversation_type                   1118       171   650.588288\n",
       "nursing, professional_type           281        33   625.808789\n",
       "famous man_agentType                 712       129   615.006161\n",
       "officer, military_agentType          540        98   614.853517\n",
       "theater_locationStructure            296        55   508.010567\n",
       "love affair_type                     400        86   507.695122\n",
       "performance_type                     384        84   496.423028\n",
       "brother_agentType                    407        92   489.131186\n",
       "town_locationSetting                 553       131   469.158442\n",
       "male adult, other_agentType          627       149   451.213525\n",
       "royalty, female_agentType            354        87   445.217652\n",
       " _note                               192        31   439.602796\n",
       "mother_agentType                     567       143   431.339847\n",
       "clergyman or clergy_agentType        503       130   430.593478"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_by_counts = pd.concat([term_freq,doc_count],axis = 1)\n",
    "\n",
    "group_by_counts.columns = ['Term_freq','Doc_freq']\n",
    "group_by_counts['tf_idf'] = pd.DataFrame(group_by_counts['Term_freq'] * np.log(total_docs/group_by_counts['Doc_freq']) )\n",
    "\n",
    "group_by_counts.sort_values(['tf_idf'],ascending=False)[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bio_response = pd.DataFrame(bess_reponse.groupby(['Response'])['Bio_col_para_id'].apply(lambda x: len(np.unique(x))))\n",
    "# bio_response.sort_values(['Bio_col_para_id'],ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Creating the Respone Variable for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Select the event for building the model\n",
    "reponse_required = 'lover, male, named_agentType'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "reponse_required_to_merge = bess_reponse[bess_reponse.Response == reponse_required]\n",
    "\n",
    "##### Merging the features and the response dataset\n",
    "text_data_merge = pd.merge(text_data_sentence, reponse_required_to_merge.drop_duplicates(),\\\n",
    "                     how = 'left', left_on=['CollectionID','BiographyID','ParagraphNo'],\n",
    "                         right_on=['collectionID','biographyID','para no'])\n",
    "\n",
    "\n",
    "########## Final Data Frame #############\n",
    "final_data_frame = text_data_merge.loc[:,['ParagraphText','Response']]\n",
    "\n",
    "final_data_frame['Response_binary'] = np.where(final_data_frame.Response.isnull(),0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Distribution of the Response variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16054\n",
       "1      583\n",
       "Name: Response_binary, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data_frame.Response_binary.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Prepocessing the Paragraph Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.1 StopWord collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting stop words - High Frequency and Low Frequency word list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "tokenized_para = final_data_frame.ParagraphText.apply(word_tokenize)\n",
    "\n",
    "all_sent = [words for each_sent in tokenized_para for words in each_sent]\n",
    "\n",
    "count_dict = Counter(all_sent)\n",
    "\n",
    "high_freq_words = [word for (word,count) in count_dict.most_common(500)]\n",
    "\n",
    "less_freq_words = []\n",
    "threshold = 5\n",
    "\n",
    "for k,v in count_dict.items():\n",
    "    \n",
    "    if v < threshold:\n",
    "        less_freq_words.append(k)\n",
    "\n",
    "        \n",
    "######### List of all stop words ##########\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(high_freq_words)\n",
    "stop_words.extend(less_freq_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Creating Training and Test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(final_data_frame.ParagraphText ,final_data_frame.Response_binary,\n",
    "                                                    test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Splitting the dataset into two categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bin_1 = X_train[y_train == 1]\n",
    "data_bin_0 = X_train[y_train == 0]\n",
    "\n",
    "dict_bin_1_tokens = word_tokenize(' '.join(data_bin_1))\n",
    "dict_bin_0_tokens = word_tokenize(' '.join(data_bin_0))\n",
    "\n",
    "dictionary_bin_1 = Counter([each for each in dict_bin_1_tokens if each not in stop_words])\n",
    "dictionary_bin_0 = Counter([each for each in dict_bin_0_tokens if each not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Creating a dataframe of probabilites ######################\n",
    "vocab_size = sum(dictionary_bin_1.values())\n",
    "for k,v in dictionary_bin_1.items():\n",
    "    dictionary_bin_1[k] = v/vocab_size\n",
    "    \n",
    "vocab_size_0 = sum(dictionary_bin_0.values())\n",
    "for k_0,v_0 in dictionary_bin_0.items():\n",
    "    dictionary_bin_0[k_0] = v_0/vocab_size_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Creating a dictionary of all the words in each of the binary category 1 and 0 ##############\n",
    "\n",
    "bin_1_value = X_test.apply(lambda x: \\\n",
    "                           sum([dictionary_bin_1[each] if (each in dictionary_bin_1.keys() and each not in stop_words)\\\n",
    "                                else 0 for each in word_tokenize(x)]))\n",
    "\n",
    "bin_0_value = X_test.apply(lambda x: \\\n",
    "                           sum([dictionary_bin_0[each] if (each in dictionary_bin_0.keys() and each not in stop_words)\\\n",
    "                                else 0 for each in word_tokenize(x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame([bin_1_value,bin_0_value]).T\n",
    "df_result.columns = ['bin_1_value','bin_0_value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Language Model Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1188"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_result.bin_0_value < df_result.bin_1_value).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Accuracy and Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.69711538461539"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * (df_result.bin_0_value < df_result.bin_1_value).sum()/len(df_result.bin_1_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3197\n",
       "1     131\n",
       "Name: Response_binary, dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8792067307692307"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "preds = (df_result.bin_0_value < df_result.bin_1_value).astype('int')\n",
    "(preds == y_test).sum()/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2840,  357],\n",
       "       [  45,   86]], dtype=int64)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin_1_value</th>\n",
       "      <th>bin_0_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16621</th>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.000187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7057</th>\n",
       "      <td>0.017422</td>\n",
       "      <td>0.013946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5704</th>\n",
       "      <td>0.035992</td>\n",
       "      <td>0.032447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14089</th>\n",
       "      <td>0.006956</td>\n",
       "      <td>0.004930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7959</th>\n",
       "      <td>0.008679</td>\n",
       "      <td>0.008282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bin_1_value  bin_0_value\n",
       "16621     0.000255     0.000187\n",
       "7057      0.017422     0.013946\n",
       "5704      0.035992     0.032447\n",
       "14089     0.006956     0.004930\n",
       "7959      0.008679     0.008282"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result[df_result.bin_0_value < df_result.bin_1_value].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Considering the words with higher probability in 1 and 0\n",
    "\n",
    "primary_words = []\n",
    "\n",
    "for each in dictionary_bin_0.keys():\n",
    "    if dictionary_bin_0[each] < dictionary_bin_1[each]:\n",
    "        primary_words.append(each)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Significant Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ostensibly',\n",
       " 'plan',\n",
       " 'gentle-',\n",
       " 'California',\n",
       " 'union',\n",
       " 'believed',\n",
       " 'plot',\n",
       " 'hunt',\n",
       " 'recognize',\n",
       " 'blood',\n",
       " 'mistress',\n",
       " 'Grass',\n",
       " 'Valley',\n",
       " 'coup',\n",
       " 'celebrity',\n",
       " 'adventure',\n",
       " 'Besides',\n",
       " 'preliminary',\n",
       " 'expenses',\n",
       " 'jewellery',\n",
       " 'Trinity',\n",
       " 'art',\n",
       " 'heroine',\n",
       " 'forsook',\n",
       " 'offered',\n",
       " 'permission',\n",
       " 'struck',\n",
       " 'Richard',\n",
       " 'hit',\n",
       " 'seem',\n",
       " 'trial',\n",
       " 'bear',\n",
       " 'preparing',\n",
       " '1837',\n",
       " 'attached',\n",
       " 'affection',\n",
       " 'Aunt',\n",
       " 'trace',\n",
       " 'Byron',\n",
       " 'Moore',\n",
       " 'drove',\n",
       " 'Dublin',\n",
       " 'arms',\n",
       " 'fashion',\n",
       " 'gatherings',\n",
       " '14',\n",
       " 'December',\n",
       " '23',\n",
       " 'advanced',\n",
       " 'odd',\n",
       " 'beginning',\n",
       " 'career',\n",
       " 'destiny',\n",
       " 'quickly',\n",
       " 'aside',\n",
       " 'effect',\n",
       " 'instrument',\n",
       " 'talking',\n",
       " 'Mme',\n",
       " 'Conti',\n",
       " 'secret',\n",
       " 'Court',\n",
       " 'pierced',\n",
       " 'actually',\n",
       " 'faltered',\n",
       " 'dropped',\n",
       " 'cheque',\n",
       " 'Robert',\n",
       " 'Blue',\n",
       " 'late',\n",
       " 'sums',\n",
       " 'flag',\n",
       " 'describes',\n",
       " 'feelings',\n",
       " 'keys',\n",
       " 'lover',\n",
       " 'Bastille',\n",
       " 'winning',\n",
       " \"d'Aubray\",\n",
       " 'forgiveness',\n",
       " 'utterly',\n",
       " 'happiness',\n",
       " 'reformed',\n",
       " 'favour',\n",
       " 'sup-',\n",
       " 'wealth',\n",
       " 'devotion',\n",
       " 'save',\n",
       " 'liked',\n",
       " 'retained',\n",
       " 'finest',\n",
       " 'moved',\n",
       " 'grace',\n",
       " 'queen',\n",
       " 'rival',\n",
       " 'proportions',\n",
       " 'figure',\n",
       " 'improbable',\n",
       " 'arrested',\n",
       " 'intervened',\n",
       " 'secure',\n",
       " 'release',\n",
       " 'debts',\n",
       " 'remained',\n",
       " 'striking',\n",
       " 'supposing',\n",
       " 'intellectual',\n",
       " 'continued',\n",
       " 'actual',\n",
       " 'treatise',\n",
       " 'extreme',\n",
       " 'fabric',\n",
       " 'greatest',\n",
       " 'tranquil',\n",
       " 'exquisite',\n",
       " 'believe',\n",
       " 'violent',\n",
       " 'stones',\n",
       " 'endure',\n",
       " 'silence',\n",
       " 'sincerity',\n",
       " 'self',\n",
       " 'conviction',\n",
       " 'minds',\n",
       " 'worth',\n",
       " 'listening',\n",
       " 'conduct',\n",
       " 'refusing',\n",
       " 'recognise',\n",
       " 'owned',\n",
       " 'caused',\n",
       " 'share',\n",
       " 'behind',\n",
       " 'door',\n",
       " 'wearing',\n",
       " 'nightly',\n",
       " 'agreed',\n",
       " 'marry',\n",
       " '1805',\n",
       " 'regularly',\n",
       " 'fearful',\n",
       " 'communication',\n",
       " 'complain',\n",
       " 'offer',\n",
       " 'guineas',\n",
       " 'cup',\n",
       " 'relating',\n",
       " 'circumstance',\n",
       " 'dying',\n",
       " 'gentle',\n",
       " 'depressed',\n",
       " 'assured',\n",
       " 'acted',\n",
       " 'gratefully',\n",
       " 'accepted',\n",
       " 'proved',\n",
       " 'adequate',\n",
       " 'Words',\n",
       " 'equalled',\n",
       " 'Love',\n",
       " 'Colonel',\n",
       " 'Thomas',\n",
       " 'graceful',\n",
       " 'person',\n",
       " 'match',\n",
       " 'mothers',\n",
       " 'usual',\n",
       " 'gentlemen',\n",
       " 'exercises',\n",
       " 'Soon',\n",
       " 'determined',\n",
       " 'travel',\n",
       " 'forming',\n",
       " 'advised',\n",
       " 'Richmond',\n",
       " 'court',\n",
       " 'attracted',\n",
       " 'Mr',\n",
       " 'pretensions',\n",
       " 'abundant',\n",
       " 'attentions',\n",
       " 'wealthy',\n",
       " 'involving',\n",
       " 'leaving',\n",
       " 'retired',\n",
       " 'attacks',\n",
       " 'September',\n",
       " 'Both',\n",
       " 'realised',\n",
       " 'understood',\n",
       " 'Â£30,000',\n",
       " 'different',\n",
       " 'Austria',\n",
       " 'deadly',\n",
       " 'cheer',\n",
       " 'receive',\n",
       " 'break',\n",
       " 'sacrificed',\n",
       " 'wants',\n",
       " 'carry',\n",
       " 'month',\n",
       " 'news',\n",
       " 'happening',\n",
       " 'Katherine',\n",
       " 'hastened',\n",
       " 'paid',\n",
       " 'sight',\n",
       " 'conspirators',\n",
       " 'decided',\n",
       " 'longed',\n",
       " 'arrived',\n",
       " 'By',\n",
       " 'busily',\n",
       " 'engaged',\n",
       " 'writing',\n",
       " 'committing',\n",
       " 'nearest',\n",
       " 'chance',\n",
       " 'Victoria',\n",
       " 'Duchess',\n",
       " 'Each',\n",
       " 'gardens',\n",
       " 'valley',\n",
       " 'profession',\n",
       " 'fallen',\n",
       " 'darkness',\n",
       " 'morbid',\n",
       " 'despair',\n",
       " 'Through',\n",
       " 'dreary',\n",
       " 'endured',\n",
       " 'unspeakable',\n",
       " 'agonies',\n",
       " 'anguish',\n",
       " 'servants',\n",
       " 'cut',\n",
       " 'impatient',\n",
       " 'lack',\n",
       " 'rush',\n",
       " 'hour',\n",
       " 'popular',\n",
       " 'saying',\n",
       " 'heads',\n",
       " 'catch',\n",
       " 'yard',\n",
       " 'policemen',\n",
       " 'abroad',\n",
       " 'attraction',\n",
       " 'anchor',\n",
       " 'recovered',\n",
       " 'sources',\n",
       " 'editor',\n",
       " 'hero',\n",
       " 'beyond',\n",
       " 'widely',\n",
       " 'brother-in-law',\n",
       " 'legitimate',\n",
       " 'natural',\n",
       " 'Rome',\n",
       " 'mercifully',\n",
       " 'delivered',\n",
       " 'threatened',\n",
       " 'dangerous',\n",
       " 'restlessness',\n",
       " 'Nothing',\n",
       " 'served',\n",
       " 'loyalty',\n",
       " 'free',\n",
       " 'Great',\n",
       " 'European',\n",
       " 'throne',\n",
       " 'chosen',\n",
       " 'scheme',\n",
       " 'Earl',\n",
       " 'Horace',\n",
       " 'Emily',\n",
       " 'Irish',\n",
       " 'medium',\n",
       " 'H.',\n",
       " 'Tuesday',\n",
       " 'Ireland',\n",
       " 'March',\n",
       " '1859',\n",
       " 'collector',\n",
       " 'named',\n",
       " 'pet',\n",
       " 'cards',\n",
       " 'kingdom',\n",
       " 'recklessness',\n",
       " 'Frenchwoman',\n",
       " '18',\n",
       " 'love-affair',\n",
       " 'lovers',\n",
       " 'description',\n",
       " 'hair',\n",
       " 'teeth',\n",
       " 'Ã©tait',\n",
       " 'et',\n",
       " 'reassure',\n",
       " 'Gabrielle',\n",
       " 'slender',\n",
       " 'stroke',\n",
       " 'beauties',\n",
       " 'Gallic',\n",
       " 'charms',\n",
       " 'lingered',\n",
       " 'Peg',\n",
       " 'colleague',\n",
       " 'Together',\n",
       " 'openly',\n",
       " 'avowed',\n",
       " 'postponed',\n",
       " 'Always',\n",
       " 'Garrick',\n",
       " 'suggestion',\n",
       " 'thirty-three',\n",
       " '2',\n",
       " 'tragic',\n",
       " 'mausoleum',\n",
       " 'partly',\n",
       " 'yellow',\n",
       " 'pall',\n",
       " 'embroidered',\n",
       " 'Imperial',\n",
       " 'gold',\n",
       " 'legs',\n",
       " 'injured',\n",
       " 'telling',\n",
       " 'question',\n",
       " 'reply',\n",
       " 'gently',\n",
       " 'gazed',\n",
       " 'fellow',\n",
       " 'wanted',\n",
       " 'whether',\n",
       " 'possibility',\n",
       " 'saving',\n",
       " 'knowing',\n",
       " 'entered',\n",
       " 'linked',\n",
       " 'subdued',\n",
       " 'strongest',\n",
       " 'passions',\n",
       " 'restrained',\n",
       " 'strain',\n",
       " 'knee',\n",
       " 'Well',\n",
       " 'beneath',\n",
       " 'melting',\n",
       " 'bliss',\n",
       " 'admirer',\n",
       " 'Woffington',\n",
       " 'Hallam',\n",
       " 'ture',\n",
       " 'You',\n",
       " 'tense',\n",
       " 'Here',\n",
       " 'standing',\n",
       " 'legacy',\n",
       " 'lovingly',\n",
       " 'accepting',\n",
       " 'sake',\n",
       " 'tie',\n",
       " 'clever',\n",
       " 'spies',\n",
       " 'captivate',\n",
       " 'easily',\n",
       " 'enamoured',\n",
       " 'glean',\n",
       " 'secrets',\n",
       " 'attendant',\n",
       " 'ran',\n",
       " 'instruments',\n",
       " 'double',\n",
       " 'stars',\n",
       " 'search',\n",
       " 'hardship',\n",
       " 'example',\n",
       " 'motion',\n",
       " 'bred',\n",
       " 'caught',\n",
       " 'spoiled',\n",
       " 'failed',\n",
       " 'monthly',\n",
       " 'naval',\n",
       " 'warmly',\n",
       " 'welcomed',\n",
       " 'First',\n",
       " 'wounded',\n",
       " 'comrade',\n",
       " 'newly',\n",
       " 'middle',\n",
       " 'upper',\n",
       " 'willing',\n",
       " 'maid',\n",
       " 'honor',\n",
       " 'Walpole',\n",
       " 'dealt',\n",
       " 'Mann',\n",
       " 'Pitt',\n",
       " 'sensation',\n",
       " 'George',\n",
       " 'II',\n",
       " 'speaks',\n",
       " 'gracious',\n",
       " 'booths',\n",
       " 'ac-',\n",
       " 'privy',\n",
       " 'civil',\n",
       " 'list',\n",
       " 'â\\x80\\x94a',\n",
       " 'monstrous',\n",
       " 'proposed',\n",
       " 're-',\n",
       " 'instantly',\n",
       " 'observes',\n",
       " 'monster',\n",
       " 'painted',\n",
       " 'largely',\n",
       " 'drawing-room',\n",
       " 'gallant',\n",
       " 'strode',\n",
       " 'Chudleigh',\n",
       " 'hoped',\n",
       " 'kiss',\n",
       " 'kissed',\n",
       " 'historic',\n",
       " 'Why',\n",
       " 'title',\n",
       " 'ing',\n",
       " 'modified',\n",
       " 'brilliant',\n",
       " 'appearing',\n",
       " 'be-',\n",
       " 'famous',\n",
       " 'Doctor',\n",
       " 'wont',\n",
       " 'call',\n",
       " 'beheld',\n",
       " 'fury',\n",
       " 'disposed',\n",
       " 'dress',\n",
       " 'sacrifice',\n",
       " 'victim',\n",
       " 'maids',\n",
       " 'strictest',\n",
       " 'offended',\n",
       " 'resembled',\n",
       " 'horses',\n",
       " 'mark',\n",
       " 'pistols',\n",
       " 'creating',\n",
       " 'pride',\n",
       " 'scandal',\n",
       " 'True',\n",
       " 'scored',\n",
       " 'notable',\n",
       " 'wits',\n",
       " 'Chesterfield',\n",
       " 'play',\n",
       " 'Do',\n",
       " 'lord',\n",
       " 'ship',\n",
       " 'casually',\n",
       " 'mean',\n",
       " 'en-',\n",
       " 'blades',\n",
       " 'incomparable',\n",
       " 'dis-',\n",
       " 'behavior',\n",
       " 'scolded',\n",
       " 'tion',\n",
       " 'fortune',\n",
       " 'rebuke',\n",
       " 'Ã',\n",
       " 'twentieth',\n",
       " 'Antwerp',\n",
       " 'really',\n",
       " 'pro-',\n",
       " 'roof',\n",
       " 'rich',\n",
       " 'handsome',\n",
       " 'Presently',\n",
       " 'aware',\n",
       " 'warm',\n",
       " 'fingers',\n",
       " 'fled',\n",
       " 'Alas',\n",
       " 'surprised',\n",
       " 'knees',\n",
       " 'Away',\n",
       " 'apparently',\n",
       " 'conveyed',\n",
       " 'charmer',\n",
       " 'somewhere',\n",
       " 'ment',\n",
       " 'reminded',\n",
       " 'explained',\n",
       " 'lose',\n",
       " 'likely',\n",
       " 'obtain',\n",
       " 'majority',\n",
       " 'consolation',\n",
       " 'presumably',\n",
       " 'dismay',\n",
       " 'dissolute',\n",
       " 'livres',\n",
       " 'roughly',\n",
       " 'excess',\n",
       " 'solicitude',\n",
       " 'future',\n",
       " 'Perhaps',\n",
       " 'Arrived',\n",
       " 'persisted',\n",
       " 'thoughts',\n",
       " 'marrying',\n",
       " 'crossed',\n",
       " 'broke',\n",
       " 'rapidly',\n",
       " 'refused',\n",
       " 'deserted',\n",
       " 'simpler',\n",
       " 'insatiable',\n",
       " 'matter',\n",
       " 'deserve',\n",
       " 'sweeter',\n",
       " 'rising',\n",
       " 'ardently',\n",
       " 'restraints',\n",
       " 'convention',\n",
       " 'dered',\n",
       " 'doubly',\n",
       " 'delicious',\n",
       " 'Betty',\n",
       " 'listened',\n",
       " 'horror',\n",
       " 'speed',\n",
       " 'Captain',\n",
       " 'Victorian',\n",
       " 'rose',\n",
       " 'humour',\n",
       " 'path',\n",
       " 'untiring',\n",
       " 'in-',\n",
       " 'ness',\n",
       " 'intimate',\n",
       " 'assumed',\n",
       " 'inevitable',\n",
       " 'realized',\n",
       " 'fuel',\n",
       " 'stuffed',\n",
       " 'San',\n",
       " 'Francisco',\n",
       " 'astonishing',\n",
       " 'romance',\n",
       " 'humor',\n",
       " 'dragged',\n",
       " 'them-',\n",
       " 'selves',\n",
       " 'plunge',\n",
       " 'clothed',\n",
       " 'conventional',\n",
       " 'gear',\n",
       " 'summoned',\n",
       " 'Bar',\n",
       " 'step',\n",
       " 'cap',\n",
       " 'veil',\n",
       " 'size',\n",
       " 'skin',\n",
       " 'vivacity',\n",
       " 'fascination',\n",
       " 'agreeable',\n",
       " 'allowed',\n",
       " 'daunted',\n",
       " 'embarrassed',\n",
       " 'Going',\n",
       " 'Genoa',\n",
       " 'Venice',\n",
       " 'Before',\n",
       " 'Europe',\n",
       " 'finer',\n",
       " 'view',\n",
       " 'attacked',\n",
       " 'criticism',\n",
       " 'determine',\n",
       " 'hated',\n",
       " 'excuses',\n",
       " 'younger',\n",
       " 'situation',\n",
       " 'Mistress',\n",
       " 'practised',\n",
       " 'ceremony',\n",
       " 'reality',\n",
       " 'personages',\n",
       " 'seventeen',\n",
       " 'fulfilled',\n",
       " 'Beside',\n",
       " 'suspense',\n",
       " 'preserved',\n",
       " 'calmness',\n",
       " 'failure',\n",
       " 'sinking',\n",
       " 'rushing',\n",
       " 'tears',\n",
       " 'suitors',\n",
       " 'importance',\n",
       " 'Irving',\n",
       " 'genius',\n",
       " 'fear',\n",
       " 'draw',\n",
       " 'averse',\n",
       " 'turn',\n",
       " 'common',\n",
       " 'amused',\n",
       " 'favourably',\n",
       " 'none',\n",
       " 'addressed',\n",
       " 'Three',\n",
       " 'Ninon',\n",
       " 'scrawled',\n",
       " 'noticeable',\n",
       " 'trouble',\n",
       " 'sheer',\n",
       " 'commission',\n",
       " 'matters',\n",
       " 'weigh',\n",
       " 'pushed',\n",
       " 'stood',\n",
       " 'convent',\n",
       " 'instead',\n",
       " 'Under',\n",
       " 'direction',\n",
       " 'Not',\n",
       " 'David',\n",
       " 'Dubois',\n",
       " 'promise',\n",
       " 'truth',\n",
       " 'blow',\n",
       " 'nervous',\n",
       " 'Moreover',\n",
       " 'fearless',\n",
       " 'dancing',\n",
       " 'struggles',\n",
       " 'surprise',\n",
       " 'supposed',\n",
       " 'verge',\n",
       " 'Oh',\n",
       " 'entering',\n",
       " 'cry',\n",
       " 'road',\n",
       " 'bronze',\n",
       " 'purple',\n",
       " 'robes',\n",
       " 'palace',\n",
       " 'wine',\n",
       " 'yards',\n",
       " 'guest',\n",
       " 'sheathed',\n",
       " 'killed',\n",
       " 'single',\n",
       " 'fire',\n",
       " 'ful',\n",
       " 'Lincolnshire',\n",
       " 'principal',\n",
       " 'esteem',\n",
       " 'conceived',\n",
       " '1841',\n",
       " 'arranged',\n",
       " '1789',\n",
       " 'Perth',\n",
       " 'thither',\n",
       " 'proceeded',\n",
       " 'attachment',\n",
       " 'acquaintance',\n",
       " 'respect',\n",
       " 'independence',\n",
       " 'opinion',\n",
       " 'thence',\n",
       " 'pay',\n",
       " 'wishes',\n",
       " 'accordingly',\n",
       " 'rejected',\n",
       " 'parting',\n",
       " 'sound',\n",
       " 'July',\n",
       " '1791',\n",
       " 'offering',\n",
       " 'consent',\n",
       " 'outline',\n",
       " 'Biography',\n",
       " 'pined',\n",
       " 'adding',\n",
       " 'prostrated',\n",
       " 'change',\n",
       " 'discovered',\n",
       " 'entrusted',\n",
       " '17',\n",
       " 'played',\n",
       " 'Covent',\n",
       " 'Garden',\n",
       " 'Throughout',\n",
       " 'comedy',\n",
       " 'wave',\n",
       " 'frantic',\n",
       " 'buy',\n",
       " 'content',\n",
       " 'newspaper',\n",
       " 'editors',\n",
       " 'clamorous',\n",
       " 'outrage',\n",
       " 'shot',\n",
       " 'fought',\n",
       " 'battle',\n",
       " 'Fort',\n",
       " 'myth',\n",
       " 'quitted',\n",
       " 'forever',\n",
       " 'Sam',\n",
       " 'West',\n",
       " 'darkly',\n",
       " 'confounded',\n",
       " 'destroyed',\n",
       " 'plainly',\n",
       " 'pupil',\n",
       " 'literature',\n",
       " 'learned',\n",
       " 'penetrated',\n",
       " 'Land',\n",
       " 'strange',\n",
       " 'dim',\n",
       " 'shadows',\n",
       " 'dreams',\n",
       " 'aching',\n",
       " 'bethought',\n",
       " 'Or',\n",
       " 'marked',\n",
       " 'Who',\n",
       " 'reappeared',\n",
       " 'stairs',\n",
       " 'jewels',\n",
       " 'Burr',\n",
       " 'lightly',\n",
       " 'gether',\n",
       " 'stationed',\n",
       " 'con-',\n",
       " 'acting',\n",
       " 'Cheltenham',\n",
       " 'scene',\n",
       " 'miserable',\n",
       " 'drama',\n",
       " 'Jordan',\n",
       " 'Devil',\n",
       " 'fatal',\n",
       " 'Clarence',\n",
       " 'inform',\n",
       " 'interview',\n",
       " 'unfortunate',\n",
       " 'theatre',\n",
       " 'alive',\n",
       " 'struggled',\n",
       " 'accuse',\n",
       " 'laughing',\n",
       " 'laugh',\n",
       " 'resulted',\n",
       " 'actress',\n",
       " 'altered',\n",
       " 'crying',\n",
       " 'Whenever',\n",
       " 'Mlle',\n",
       " 'Lenclos',\n",
       " 'courted',\n",
       " \"D'Orsay\",\n",
       " 'immensely',\n",
       " 'Marguerite',\n",
       " 'frankly',\n",
       " 'adored',\n",
       " 'youth',\n",
       " 'Blessington',\n",
       " 'consented',\n",
       " 'siege',\n",
       " 'longer',\n",
       " 'projected',\n",
       " 'celebrated',\n",
       " 'Frankfort',\n",
       " 'century',\n",
       " 'Government',\n",
       " 'area',\n",
       " 'welcome',\n",
       " 'suite',\n",
       " 'closed',\n",
       " 'sadly',\n",
       " 'Dowager',\n",
       " 'Priory',\n",
       " 'stages',\n",
       " 'smooth',\n",
       " 'wound',\n",
       " 'supported',\n",
       " 'Louvre',\n",
       " 'wore',\n",
       " 'breasts',\n",
       " 'escape',\n",
       " 'engraved',\n",
       " 'jewel',\n",
       " 'thin',\n",
       " 'la',\n",
       " 'Meanwhile',\n",
       " 'managed',\n",
       " 'Craigie',\n",
       " 'hold',\n",
       " 'invited',\n",
       " 'meeting',\n",
       " 'proceedings',\n",
       " 'guests',\n",
       " 'lowly',\n",
       " 'Those',\n",
       " 'Dear',\n",
       " 'Their',\n",
       " 'abused',\n",
       " 'ugly',\n",
       " 'fleet',\n",
       " 'fish',\n",
       " 'cheap',\n",
       " 'rate',\n",
       " 'ComÃ©die',\n",
       " 'audience',\n",
       " 'dramatic',\n",
       " 'dozen',\n",
       " 'marveled',\n",
       " 'singing',\n",
       " 'hood',\n",
       " 'La',\n",
       " 'Adrienne',\n",
       " 'compared',\n",
       " 'Georges',\n",
       " 'tragedy',\n",
       " 'vehicle',\n",
       " 'technique',\n",
       " 'rivals',\n",
       " 'plans',\n",
       " 'destroy',\n",
       " 'provinces',\n",
       " 'teen',\n",
       " 'reason',\n",
       " 'conquest',\n",
       " 'com-',\n",
       " 'perfection',\n",
       " 'uniformly',\n",
       " 'un-',\n",
       " 'cultivation',\n",
       " 'impassioned',\n",
       " 'Platonic',\n",
       " 'bought',\n",
       " 'street',\n",
       " 'supremely',\n",
       " 'tolerated',\n",
       " 'hint',\n",
       " 'pos-',\n",
       " 'sessed',\n",
       " 'pair',\n",
       " 'brilliants',\n",
       " 'sought',\n",
       " 'prized',\n",
       " 'Dukes',\n",
       " 'Richelieu',\n",
       " 'Marquis',\n",
       " 'ruled',\n",
       " 'unhappy',\n",
       " 'master',\n",
       " 'physically',\n",
       " 'overwhelmingly',\n",
       " 'commanded',\n",
       " 'admirably',\n",
       " 'audible',\n",
       " 'clearly',\n",
       " 'today',\n",
       " 'remains',\n",
       " 'Minor',\n",
       " 'learnt',\n",
       " 'faced',\n",
       " 'suspects',\n",
       " 'abashed',\n",
       " 'magnificence',\n",
       " 'spring',\n",
       " 'secretly',\n",
       " 'divinity',\n",
       " 'understanding',\n",
       " 'drew',\n",
       " 'momentary',\n",
       " 'intellect',\n",
       " 'affair',\n",
       " 'Nicolas',\n",
       " 'ambitious',\n",
       " 'unmercifully',\n",
       " 'terribly',\n",
       " 'pleased',\n",
       " 'causes',\n",
       " 'temporarily',\n",
       " 'whim',\n",
       " 'changing',\n",
       " 'conversation',\n",
       " 'novels',\n",
       " 'Whereat',\n",
       " 'boredom',\n",
       " 'assailed',\n",
       " 'danger',\n",
       " 'Sydney',\n",
       " 'ments',\n",
       " 'pause',\n",
       " 'shown',\n",
       " 'maintenance',\n",
       " 'indispensable',\n",
       " 'virtue',\n",
       " 'deserts',\n",
       " 'stopped',\n",
       " 'built',\n",
       " 'passes',\n",
       " 'poured',\n",
       " 'milk',\n",
       " 'prevailed',\n",
       " 'toward',\n",
       " 'Theatre',\n",
       " 'except',\n",
       " 'disguise',\n",
       " 'walk',\n",
       " 'decent',\n",
       " 'masked',\n",
       " 'belle',\n",
       " 'passive',\n",
       " 'beau',\n",
       " 'carpenter',\n",
       " 'spoilt',\n",
       " 'Scotland',\n",
       " 'creep',\n",
       " 'fiction',\n",
       " 'attitude',\n",
       " 'certainly',\n",
       " 'dressed',\n",
       " 'dresses',\n",
       " 'smile',\n",
       " 'C.',\n",
       " 'collected',\n",
       " 'zealous',\n",
       " 'sat',\n",
       " 'bedside',\n",
       " 'utter',\n",
       " 'haunt',\n",
       " 'ap-',\n",
       " 'supreme',\n",
       " 'frenzy',\n",
       " 'interrupted',\n",
       " 'animal',\n",
       " 'creature',\n",
       " 'sheep',\n",
       " 'contrived',\n",
       " 'somehow',\n",
       " 'corner',\n",
       " 'sixth',\n",
       " 'pictures',\n",
       " 'salon',\n",
       " 'drawing',\n",
       " 'displayed',\n",
       " 'acknowledged',\n",
       " 'escaped',\n",
       " 'imprisonment',\n",
       " 'pastures',\n",
       " 'pronounced',\n",
       " 'admiring',\n",
       " 'achieved',\n",
       " 'muscles',\n",
       " 'breath',\n",
       " 'web',\n",
       " 'incident',\n",
       " 'judicious',\n",
       " 'Christmas',\n",
       " 'fourth',\n",
       " 'Better',\n",
       " 'embarked',\n",
       " 'Again',\n",
       " 'enormous',\n",
       " 'abode',\n",
       " 'universe',\n",
       " 'scattered',\n",
       " 'villages',\n",
       " 'opposite',\n",
       " 'ought',\n",
       " 'slave',\n",
       " 'Carlisle',\n",
       " 'formation',\n",
       " 'recalls',\n",
       " 'farmer',\n",
       " 'arrive',\n",
       " 'amazing',\n",
       " 'watched',\n",
       " 'contemplated',\n",
       " 'dragging',\n",
       " 'companion',\n",
       " 'lying',\n",
       " 'Napoleon',\n",
       " 'Among',\n",
       " ...]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primary_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Modification - Including the words that are present for the binary class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bin_1 = X_train[y_train == 1]\n",
    "data_bin_0 = X_train[y_train == 0]\n",
    "\n",
    "dict_bin_1_tokens = word_tokenize(' '.join(data_bin_1))\n",
    "dict_bin_0_tokens = word_tokenize(' '.join(data_bin_0))\n",
    "\n",
    "dictionary_bin_1 = Counter([each for each in dict_bin_1_tokens if each not in stop_words])\n",
    "dictionary_bin_0 = Counter([each for each in dict_bin_0_tokens if each not in stop_words and each in dict_bin_1_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Creating a dataframe of probabilites ######################\n",
    "\n",
    "vocab_size = sum(dictionary_bin_1.values())\n",
    "for k,v in dictionary_bin_1.items():\n",
    "    dictionary_bin_1[k] = v/vocab_size\n",
    "    \n",
    "vocab_size_0 = sum(dictionary_bin_0.values())\n",
    "for k_0,v_0 in dictionary_bin_0.items():\n",
    "    dictionary_bin_0[k_0] = v_0/vocab_size_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Creating a dictionary of all the words in each of the binary category 1 and 0 ##############\n",
    "\n",
    "bin_1_value = X_test.apply(lambda x: \\\n",
    "                           sum([dictionary_bin_1[each] if (each in dictionary_bin_1.keys() and each not in stop_words)\\\n",
    "                                else 0 for each in word_tokenize(x)]))\n",
    "\n",
    "bin_0_value = X_test.apply(lambda x: \\\n",
    "                           sum([dictionary_bin_0[each] if (each in dictionary_bin_0.keys() and each not in stop_words)\\\n",
    "                                else 0 for each in word_tokenize(x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame([bin_1_value,bin_0_value]).T\n",
    "df_result.columns = ['bin_1_value','bin_0_value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Language Model Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "443"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_result.bin_0_value < df_result.bin_1_value).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3197\n",
       "1     131\n",
       "Name: Response_binary, dtype: int64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8792067307692307"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "preds = (df_result.bin_0_value < df_result.bin_1_value).astype('int')\n",
    "(preds == y_test).sum()/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2840,  357],\n",
       "       [  45,   86]], dtype=int64)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin_1_value</th>\n",
       "      <th>bin_0_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13407</th>\n",
       "      <td>0.004340</td>\n",
       "      <td>0.002718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4384</th>\n",
       "      <td>0.000383</td>\n",
       "      <td>0.000332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13743</th>\n",
       "      <td>0.006382</td>\n",
       "      <td>0.002522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10356</th>\n",
       "      <td>0.022144</td>\n",
       "      <td>0.015319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16561</th>\n",
       "      <td>0.007020</td>\n",
       "      <td>0.002537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bin_1_value  bin_0_value\n",
       "13407     0.004340     0.002718\n",
       "4384      0.000383     0.000332\n",
       "13743     0.006382     0.002522\n",
       "10356     0.022144     0.015319\n",
       "16561     0.007020     0.002537"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result[df_result.bin_0_value < df_result.bin_1_value].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In strait-laced ways and to all demure modesty, Eliza was reared. And at fifteen she was not only the prettiest girl in Rhode Island, but one of the cleverest andâ\\x80\\x94so declared the piousâ\\x80\\x94one of the very worst. In those days and in New England, it was delightfully easy to acquire a reputation for wickedness by merely failing to conform to all the ideas of the blue-law devotees. Shan't we give Betty Bowenâ\\x80\\x94her com- monly used nameâ\\x80\\x94the benefit of the doubt?\""
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Considering the words with higher probability in 1 and 0\n",
    "\n",
    "primary_words = []\n",
    "\n",
    "for each in dictionary_bin_0.keys():\n",
    "    if dictionary_bin_0[each] < dictionary_bin_1[each]:\n",
    "        primary_words.append(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ostensibly',\n",
       " 'gentle-',\n",
       " 'California',\n",
       " 'union',\n",
       " 'plot',\n",
       " 'hunt',\n",
       " 'blood',\n",
       " 'mistress',\n",
       " 'Grass',\n",
       " 'Valley',\n",
       " 'coup',\n",
       " 'celebrity',\n",
       " 'adventure',\n",
       " 'preliminary',\n",
       " 'expenses',\n",
       " 'jewellery',\n",
       " 'Trinity',\n",
       " 'forsook',\n",
       " 'permission',\n",
       " 'Richard',\n",
       " 'hit',\n",
       " 'trial',\n",
       " 'preparing',\n",
       " '1837',\n",
       " 'Aunt',\n",
       " 'trace',\n",
       " 'Byron',\n",
       " 'Moore',\n",
       " 'drove',\n",
       " 'Dublin',\n",
       " 'arms',\n",
       " 'gatherings',\n",
       " 'December',\n",
       " '23',\n",
       " 'advanced',\n",
       " 'odd',\n",
       " 'destiny',\n",
       " 'instrument',\n",
       " 'Conti',\n",
       " 'secret',\n",
       " 'Court',\n",
       " 'pierced',\n",
       " 'faltered',\n",
       " 'dropped',\n",
       " 'cheque',\n",
       " 'Robert',\n",
       " 'sums',\n",
       " 'flag',\n",
       " 'describes',\n",
       " 'keys',\n",
       " 'lover',\n",
       " 'Bastille',\n",
       " 'winning',\n",
       " \"d'Aubray\",\n",
       " 'forgiveness',\n",
       " 'utterly',\n",
       " 'reformed',\n",
       " 'favour',\n",
       " 'sup-',\n",
       " 'wealth',\n",
       " 'devotion',\n",
       " 'queen',\n",
       " 'rival',\n",
       " 'proportions',\n",
       " 'improbable',\n",
       " 'arrested',\n",
       " 'intervened',\n",
       " 'secure',\n",
       " 'release',\n",
       " 'debts',\n",
       " 'supposing',\n",
       " 'treatise',\n",
       " 'extreme',\n",
       " 'fabric',\n",
       " 'greatest',\n",
       " 'exquisite',\n",
       " 'violent',\n",
       " 'endure',\n",
       " 'silence',\n",
       " 'sincerity',\n",
       " 'self',\n",
       " 'conviction',\n",
       " 'conduct',\n",
       " 'refusing',\n",
       " 'recognise',\n",
       " 'owned',\n",
       " 'wearing',\n",
       " 'nightly',\n",
       " 'marry',\n",
       " '1805',\n",
       " 'complain',\n",
       " 'guineas',\n",
       " 'cup',\n",
       " 'circumstance',\n",
       " 'dying',\n",
       " 'gentle',\n",
       " 'depressed',\n",
       " 'acted',\n",
       " 'proved',\n",
       " 'adequate',\n",
       " 'Words',\n",
       " 'Love',\n",
       " 'Colonel',\n",
       " 'Thomas',\n",
       " 'person',\n",
       " 'match',\n",
       " 'usual',\n",
       " 'gentlemen',\n",
       " 'exercises',\n",
       " 'travel',\n",
       " 'forming',\n",
       " 'advised',\n",
       " 'Richmond',\n",
       " 'court',\n",
       " 'attracted',\n",
       " 'pretensions',\n",
       " 'attentions',\n",
       " 'involving',\n",
       " 'retired',\n",
       " 'September',\n",
       " 'Both',\n",
       " 'realised',\n",
       " 'understood',\n",
       " 'Â£30,000',\n",
       " 'different',\n",
       " 'deadly',\n",
       " 'break',\n",
       " 'sacrificed',\n",
       " 'wants',\n",
       " 'carry',\n",
       " 'month',\n",
       " 'happening',\n",
       " 'Katherine',\n",
       " 'hastened',\n",
       " 'conspirators',\n",
       " 'decided',\n",
       " 'arrived',\n",
       " 'busily',\n",
       " 'engaged',\n",
       " 'committing',\n",
       " 'profession',\n",
       " 'morbid',\n",
       " 'despair',\n",
       " 'Through',\n",
       " 'endured',\n",
       " 'agonies',\n",
       " 'cut',\n",
       " 'impatient',\n",
       " 'lack',\n",
       " 'rush',\n",
       " 'hour',\n",
       " 'popular',\n",
       " 'heads',\n",
       " 'yard',\n",
       " 'policemen',\n",
       " 'attraction',\n",
       " 'anchor',\n",
       " 'editor',\n",
       " 'hero',\n",
       " 'widely',\n",
       " 'brother-in-law',\n",
       " 'Rome',\n",
       " 'mercifully',\n",
       " 'threatened',\n",
       " 'dangerous',\n",
       " 'Nothing',\n",
       " 'served',\n",
       " 'loyalty',\n",
       " 'free',\n",
       " 'Earl',\n",
       " 'Horace',\n",
       " 'Emily',\n",
       " 'medium',\n",
       " 'H.',\n",
       " 'Tuesday',\n",
       " 'Ireland',\n",
       " 'March',\n",
       " 'collector',\n",
       " 'cards',\n",
       " 'recklessness',\n",
       " 'Frenchwoman',\n",
       " '18',\n",
       " 'love-affair',\n",
       " 'lovers',\n",
       " 'hair',\n",
       " 'Ã©tait',\n",
       " 'et',\n",
       " 'reassure',\n",
       " 'Gabrielle',\n",
       " 'slender',\n",
       " 'stroke',\n",
       " 'beauties',\n",
       " 'Gallic',\n",
       " 'lingered',\n",
       " 'Peg',\n",
       " 'colleague',\n",
       " 'Together',\n",
       " 'openly',\n",
       " 'avowed',\n",
       " 'postponed',\n",
       " 'Always',\n",
       " 'Garrick',\n",
       " 'thirty-three',\n",
       " 'tragic',\n",
       " 'mausoleum',\n",
       " 'partly',\n",
       " 'yellow',\n",
       " 'pall',\n",
       " 'embroidered',\n",
       " 'Imperial',\n",
       " 'legs',\n",
       " 'injured',\n",
       " 'reply',\n",
       " 'gently',\n",
       " 'gazed',\n",
       " 'fellow',\n",
       " 'possibility',\n",
       " 'linked',\n",
       " 'passions',\n",
       " 'strain',\n",
       " 'Well',\n",
       " 'melting',\n",
       " 'admirer',\n",
       " 'Hallam',\n",
       " 'ture',\n",
       " 'You',\n",
       " 'tense',\n",
       " 'legacy',\n",
       " 'sake',\n",
       " 'spies',\n",
       " 'captivate',\n",
       " 'enamoured',\n",
       " 'glean',\n",
       " 'secrets',\n",
       " 'attendant',\n",
       " 'double',\n",
       " 'search',\n",
       " 'hardship',\n",
       " 'motion',\n",
       " 'bred',\n",
       " 'spoiled',\n",
       " 'naval',\n",
       " 'First',\n",
       " 'comrade',\n",
       " 'newly',\n",
       " 'upper',\n",
       " 'willing',\n",
       " 'maid',\n",
       " 'honor',\n",
       " 'Walpole',\n",
       " 'Mann',\n",
       " 'Pitt',\n",
       " 'sensation',\n",
       " 'George',\n",
       " 'II',\n",
       " 'booths',\n",
       " 'privy',\n",
       " 'â\\x80\\x94a',\n",
       " 'monstrous',\n",
       " 'proposed',\n",
       " 're-',\n",
       " 'instantly',\n",
       " 'monster',\n",
       " 'painted',\n",
       " 'gallant',\n",
       " 'strode',\n",
       " 'Chudleigh',\n",
       " 'hoped',\n",
       " 'ing',\n",
       " 'modified',\n",
       " 'brilliant',\n",
       " 'appearing',\n",
       " 'be-',\n",
       " 'beheld',\n",
       " 'fury',\n",
       " 'sacrifice',\n",
       " 'maids',\n",
       " 'strictest',\n",
       " 'offended',\n",
       " 'resembled',\n",
       " 'horses',\n",
       " 'pistols',\n",
       " 'creating',\n",
       " 'pride',\n",
       " 'scandal',\n",
       " 'True',\n",
       " 'scored',\n",
       " 'notable',\n",
       " 'wits',\n",
       " 'Chesterfield',\n",
       " 'ship',\n",
       " 'casually',\n",
       " 'en-',\n",
       " 'blades',\n",
       " 'incomparable',\n",
       " 'dis-',\n",
       " 'behavior',\n",
       " 'scolded',\n",
       " 'tion',\n",
       " 'fortune',\n",
       " 'rebuke',\n",
       " 'Ã',\n",
       " 'twentieth',\n",
       " 'Antwerp',\n",
       " 'pro-',\n",
       " 'handsome',\n",
       " 'Presently',\n",
       " 'aware',\n",
       " 'fingers',\n",
       " 'fled',\n",
       " 'Alas',\n",
       " 'surprised',\n",
       " 'knees',\n",
       " 'Away',\n",
       " 'apparently',\n",
       " 'conveyed',\n",
       " 'charmer',\n",
       " 'somewhere',\n",
       " 'ment',\n",
       " 'explained',\n",
       " 'majority',\n",
       " 'presumably',\n",
       " 'livres',\n",
       " 'roughly',\n",
       " 'excess',\n",
       " 'Perhaps',\n",
       " 'Arrived',\n",
       " 'persisted',\n",
       " 'marrying',\n",
       " 'refused',\n",
       " 'deserted',\n",
       " 'simpler',\n",
       " 'insatiable',\n",
       " 'matter',\n",
       " 'deserve',\n",
       " 'sweeter',\n",
       " 'ardently',\n",
       " 'restraints',\n",
       " 'convention',\n",
       " 'dered',\n",
       " 'doubly',\n",
       " 'delicious',\n",
       " 'Betty',\n",
       " 'listened',\n",
       " 'horror',\n",
       " 'speed',\n",
       " 'Victorian',\n",
       " 'rose',\n",
       " 'path',\n",
       " 'in-',\n",
       " 'ness',\n",
       " 'assumed',\n",
       " 'realized',\n",
       " 'fuel',\n",
       " 'stuffed',\n",
       " 'Francisco',\n",
       " 'astonishing',\n",
       " 'romance',\n",
       " 'humor',\n",
       " 'dragged',\n",
       " 'plunge',\n",
       " 'clothed',\n",
       " 'conventional',\n",
       " 'gear',\n",
       " 'Bar',\n",
       " 'cap',\n",
       " 'skin',\n",
       " 'fascination',\n",
       " 'agreeable',\n",
       " 'daunted',\n",
       " 'embarrassed',\n",
       " 'Going',\n",
       " 'Genoa',\n",
       " 'Venice',\n",
       " 'finer',\n",
       " 'attacked',\n",
       " 'determine',\n",
       " 'hated',\n",
       " 'excuses',\n",
       " 'younger',\n",
       " 'situation',\n",
       " 'Mistress',\n",
       " 'ceremony',\n",
       " 'reality',\n",
       " 'Beside',\n",
       " 'suspense',\n",
       " 'failure',\n",
       " 'sinking',\n",
       " 'rushing',\n",
       " 'Irving',\n",
       " 'averse',\n",
       " 'favourably',\n",
       " 'addressed',\n",
       " 'Ninon',\n",
       " 'scrawled',\n",
       " 'noticeable',\n",
       " 'commission',\n",
       " 'matters',\n",
       " 'weigh',\n",
       " 'pushed',\n",
       " 'convent',\n",
       " 'Not',\n",
       " 'David',\n",
       " 'Dubois',\n",
       " 'promise',\n",
       " 'blow',\n",
       " 'Moreover',\n",
       " 'dancing',\n",
       " 'struggles',\n",
       " 'supposed',\n",
       " 'verge',\n",
       " 'bronze',\n",
       " 'robes',\n",
       " 'palace',\n",
       " 'wine',\n",
       " 'yards',\n",
       " 'sheathed',\n",
       " 'killed',\n",
       " 'fire',\n",
       " 'ful',\n",
       " 'Lincolnshire',\n",
       " 'esteem',\n",
       " 'conceived',\n",
       " 'arranged',\n",
       " '1789',\n",
       " 'Perth',\n",
       " 'thither',\n",
       " 'attachment',\n",
       " 'acquaintance',\n",
       " 'independence',\n",
       " 'thence',\n",
       " 'accordingly',\n",
       " 'rejected',\n",
       " 'sound',\n",
       " 'July',\n",
       " '1791',\n",
       " 'consent',\n",
       " 'outline',\n",
       " 'Biography',\n",
       " 'pined',\n",
       " 'prostrated',\n",
       " '17',\n",
       " 'played',\n",
       " 'Covent',\n",
       " 'Garden',\n",
       " 'Throughout',\n",
       " 'comedy',\n",
       " 'clamorous',\n",
       " 'outrage',\n",
       " 'shot',\n",
       " 'fought',\n",
       " 'battle',\n",
       " 'Fort',\n",
       " 'myth',\n",
       " 'quitted',\n",
       " 'forever',\n",
       " 'darkly',\n",
       " 'confounded',\n",
       " 'plainly',\n",
       " 'pupil',\n",
       " 'penetrated',\n",
       " 'dreams',\n",
       " 'aching',\n",
       " 'bethought',\n",
       " 'marked',\n",
       " 'reappeared',\n",
       " 'stairs',\n",
       " 'jewels',\n",
       " 'Burr',\n",
       " 'gether',\n",
       " 'con-',\n",
       " 'Cheltenham',\n",
       " 'miserable',\n",
       " 'Jordan',\n",
       " 'fatal',\n",
       " 'Clarence',\n",
       " 'inform',\n",
       " 'theatre',\n",
       " 'struggled',\n",
       " 'accuse',\n",
       " 'laugh',\n",
       " 'resulted',\n",
       " 'altered',\n",
       " 'crying',\n",
       " 'courted',\n",
       " \"D'Orsay\",\n",
       " 'immensely',\n",
       " 'Marguerite',\n",
       " 'adored',\n",
       " 'youth',\n",
       " 'Blessington',\n",
       " 'consented',\n",
       " 'longer',\n",
       " 'projected',\n",
       " 'Frankfort',\n",
       " 'area',\n",
       " 'suite',\n",
       " 'sadly',\n",
       " 'Priory',\n",
       " 'stages',\n",
       " 'wound',\n",
       " 'Louvre',\n",
       " 'breasts',\n",
       " 'escape',\n",
       " 'engraved',\n",
       " 'jewel',\n",
       " 'thin',\n",
       " 'la',\n",
       " 'Meanwhile',\n",
       " 'managed',\n",
       " 'Craigie',\n",
       " 'proceedings',\n",
       " 'guests',\n",
       " 'Dear',\n",
       " 'abused',\n",
       " 'ugly',\n",
       " 'fleet',\n",
       " 'fish',\n",
       " 'rate',\n",
       " 'ComÃ©die',\n",
       " 'dramatic',\n",
       " 'marveled',\n",
       " 'La',\n",
       " 'Adrienne',\n",
       " 'compared',\n",
       " 'Georges',\n",
       " 'tragedy',\n",
       " 'vehicle',\n",
       " 'technique',\n",
       " 'rivals',\n",
       " 'destroy',\n",
       " 'provinces',\n",
       " 'teen',\n",
       " 'reason',\n",
       " 'conquest',\n",
       " 'com-',\n",
       " 'perfection',\n",
       " 'uniformly',\n",
       " 'un-',\n",
       " 'impassioned',\n",
       " 'Platonic',\n",
       " 'supremely',\n",
       " 'tolerated',\n",
       " 'hint',\n",
       " 'pos-',\n",
       " 'sessed',\n",
       " 'brilliants',\n",
       " 'sought',\n",
       " 'prized',\n",
       " 'Dukes',\n",
       " 'ruled',\n",
       " 'unhappy',\n",
       " 'master',\n",
       " 'overwhelmingly',\n",
       " 'commanded',\n",
       " 'admirably',\n",
       " 'audible',\n",
       " 'clearly',\n",
       " 'today',\n",
       " 'remains',\n",
       " 'Minor',\n",
       " 'faced',\n",
       " 'suspects',\n",
       " 'abashed',\n",
       " 'magnificence',\n",
       " 'spring',\n",
       " 'secretly',\n",
       " 'divinity',\n",
       " 'drew',\n",
       " 'momentary',\n",
       " 'affair',\n",
       " 'Nicolas',\n",
       " 'ambitious',\n",
       " 'unmercifully',\n",
       " 'causes',\n",
       " 'whim',\n",
       " 'Whereat',\n",
       " 'boredom',\n",
       " 'assailed',\n",
       " 'ments',\n",
       " 'indispensable',\n",
       " 'deserts',\n",
       " 'stopped',\n",
       " 'passes',\n",
       " 'milk',\n",
       " 'toward',\n",
       " 'Theatre',\n",
       " 'disguise',\n",
       " 'masked',\n",
       " 'belle',\n",
       " 'passive',\n",
       " 'beau',\n",
       " 'carpenter',\n",
       " 'spoilt',\n",
       " 'creep',\n",
       " 'fiction',\n",
       " 'attitude',\n",
       " 'dresses',\n",
       " 'smile',\n",
       " 'C.',\n",
       " 'bedside',\n",
       " 'haunt',\n",
       " 'ap-',\n",
       " 'supreme',\n",
       " 'interrupted',\n",
       " 'contrived',\n",
       " 'sixth',\n",
       " 'salon',\n",
       " 'displayed',\n",
       " 'acknowledged',\n",
       " 'escaped',\n",
       " 'imprisonment',\n",
       " 'pastures',\n",
       " 'achieved',\n",
       " 'muscles',\n",
       " 'breath',\n",
       " 'web',\n",
       " 'incident',\n",
       " 'judicious',\n",
       " 'fourth',\n",
       " 'Better',\n",
       " 'Again',\n",
       " 'enormous',\n",
       " 'universe',\n",
       " 'opposite',\n",
       " 'ought',\n",
       " 'Carlisle',\n",
       " 'recalls',\n",
       " 'farmer',\n",
       " 'amazing',\n",
       " 'contemplated',\n",
       " 'dragging',\n",
       " 'apartments',\n",
       " 'observer',\n",
       " 'thrown',\n",
       " 'total',\n",
       " 'misery',\n",
       " 'colossal',\n",
       " 'Justice',\n",
       " 'circulated',\n",
       " 'detection',\n",
       " 'fighting',\n",
       " 'cleared',\n",
       " 'Guard',\n",
       " 'exchanged',\n",
       " 'M.',\n",
       " 'duchess',\n",
       " 'wax',\n",
       " 'wondered',\n",
       " 'cynical',\n",
       " 'yield',\n",
       " 'passionate',\n",
       " 'amorous',\n",
       " 'sus-',\n",
       " 'move',\n",
       " 'happened',\n",
       " 'Duchy',\n",
       " 'Courland',\n",
       " 'duke',\n",
       " 'election',\n",
       " 'dukedom',\n",
       " 'Saxe',\n",
       " 'miracle',\n",
       " 'Pisa',\n",
       " 'Dick',\n",
       " 'Consul',\n",
       " 'mourning',\n",
       " 'sobbing',\n",
       " 'soundly',\n",
       " 'paying',\n",
       " 'comic',\n",
       " 'numberless',\n",
       " 'chess',\n",
       " 'ice',\n",
       " 'dismissal',\n",
       " 'prepared',\n",
       " 'warmer',\n",
       " 'favorite',\n",
       " 'drawled',\n",
       " 'herâ\\x80\\x94and',\n",
       " 'Dictionary',\n",
       " 'piqued',\n",
       " 'existed',\n",
       " 'procure',\n",
       " 'disgusted',\n",
       " 'forthwith',\n",
       " 'desperation',\n",
       " 'vanity',\n",
       " 'cruelty',\n",
       " 'fortunate',\n",
       " 'borne',\n",
       " 'excited',\n",
       " 'repugnance',\n",
       " 'foundation',\n",
       " 'grasp',\n",
       " 'safer',\n",
       " 'wiser',\n",
       " 'deceive',\n",
       " 'deceived',\n",
       " 'knight',\n",
       " 'August',\n",
       " 'Castle',\n",
       " 'gorgeous',\n",
       " 'hung',\n",
       " 'fragrant',\n",
       " 'hat',\n",
       " 'boyhood',\n",
       " 'provoking',\n",
       " 'chose',\n",
       " 'proverbial',\n",
       " '1823',\n",
       " 'favor',\n",
       " 'borrowed',\n",
       " 'sailing',\n",
       " 'strenuous',\n",
       " 'firm',\n",
       " 'glasses',\n",
       " 'immaculate',\n",
       " 'devil',\n",
       " 'Neither',\n",
       " 'points',\n",
       " 'tribunal',\n",
       " 'grey',\n",
       " 'barely',\n",
       " 'followers',\n",
       " 'fate',\n",
       " 'caste',\n",
       " 'alternatives',\n",
       " 'suicide',\n",
       " 'India',\n",
       " 'superb',\n",
       " 'Maupin',\n",
       " 'Dumeni',\n",
       " 'suddenly',\n",
       " 'ear',\n",
       " 'sword',\n",
       " 'eager',\n",
       " 'idleness',\n",
       " 'kill',\n",
       " 'dash',\n",
       " 'swear',\n",
       " 'bottom',\n",
       " 'swimming',\n",
       " 'presents',\n",
       " 'laughed',\n",
       " 'insisted',\n",
       " 'ridicule',\n",
       " 'dangerously',\n",
       " 'ribbon',\n",
       " 'chestnut',\n",
       " 'brows',\n",
       " 'sorts',\n",
       " 'Croix',\n",
       " 'inamorata',\n",
       " 'marble',\n",
       " 'excite',\n",
       " 'forgiven',\n",
       " 'Lieutenant',\n",
       " 'retreated',\n",
       " 'judicial',\n",
       " 'separation',\n",
       " 'forces',\n",
       " 'vital',\n",
       " 'officer',\n",
       " 'plead',\n",
       " 'perceive',\n",
       " 'laws',\n",
       " 'vivid',\n",
       " 'ardent',\n",
       " 'shell',\n",
       " 'plume',\n",
       " 'filed',\n",
       " 'knelt',\n",
       " 'stared',\n",
       " 'Bralez',\n",
       " 'prison',\n",
       " 'elsewhere',\n",
       " 'de-',\n",
       " 'lamentations',\n",
       " 'betray',\n",
       " 'indication',\n",
       " 'punishment',\n",
       " 'lawyer',\n",
       " 'convince',\n",
       " 'innocence',\n",
       " 'absent',\n",
       " 'twenty-four',\n",
       " 'threw',\n",
       " 'danced',\n",
       " 'cell',\n",
       " 'shuddered',\n",
       " 'averted',\n",
       " 'fanatic',\n",
       " 'blast',\n",
       " 'final',\n",
       " 'Mata',\n",
       " 'Hari',\n",
       " 'sides',\n",
       " 'weep',\n",
       " 'knows',\n",
       " 'damned',\n",
       " 'Indeed',\n",
       " 'existence',\n",
       " 'agonized',\n",
       " 'unfortunately',\n",
       " 'definite',\n",
       " 'Molly',\n",
       " 'Nancy',\n",
       " 'securing',\n",
       " 'respective',\n",
       " 'interchange',\n",
       " 'broken',\n",
       " 'sobs',\n",
       " 'elevated',\n",
       " 'drown',\n",
       " 'capacities',\n",
       " 'despite',\n",
       " 'preoccupation',\n",
       " 'belonged',\n",
       " 'suitor',\n",
       " 'intellectually',\n",
       " 'reciprocated',\n",
       " 'passion',\n",
       " 'dismissed',\n",
       " 'parcel',\n",
       " 'nobleman',\n",
       " 'Irishman',\n",
       " 'gallantry',\n",
       " 'eloping',\n",
       " 'Mountjoy',\n",
       " 'stayed',\n",
       " 'tongues',\n",
       " 'reside',\n",
       " 'lovely',\n",
       " 'atten-',\n",
       " 'widower',\n",
       " 'irony',\n",
       " 'notoriety',\n",
       " 'permitted',\n",
       " 'Pole',\n",
       " 'Henrietta',\n",
       " 'Nor',\n",
       " 'Greece',\n",
       " 'sanctity',\n",
       " 'essential',\n",
       " 'episode',\n",
       " 'acceptance',\n",
       " 'marching',\n",
       " 'regiments',\n",
       " 'an-',\n",
       " 'Aaron',\n",
       " 'Monsieur',\n",
       " 'successor',\n",
       " 'problems',\n",
       " 'niece',\n",
       " 'brief',\n",
       " 'handsomest',\n",
       " 'calm',\n",
       " 'inevitably',\n",
       " 'phrase',\n",
       " 'politics',\n",
       " 'ings',\n",
       " 'seasoned',\n",
       " 'playing',\n",
       " 'darling',\n",
       " 'breaking',\n",
       " 'intrigues',\n",
       " 'parson',\n",
       " 'Emma',\n",
       " 'hysterical',\n",
       " 'port',\n",
       " 'betrayed',\n",
       " 'joyous',\n",
       " 'capable',\n",
       " 'waxed',\n",
       " 'thriving',\n",
       " 'illicit',\n",
       " 'packed',\n",
       " 'lustre',\n",
       " 'shabby',\n",
       " 'stupid',\n",
       " 'eyelids',\n",
       " 'scorned',\n",
       " 'romances',\n",
       " 'refrained',\n",
       " 'biographers',\n",
       " 'Rosamunda',\n",
       " 'cruel',\n",
       " 'fates',\n",
       " 'Italy',\n",
       " 'sincere',\n",
       " 'lasting',\n",
       " 'renounced',\n",
       " 'fiercely',\n",
       " 'persuasion',\n",
       " 'exit',\n",
       " 'veneration',\n",
       " 'denied',\n",
       " 'grass',\n",
       " 'astray',\n",
       " 'frank',\n",
       " 'avowal',\n",
       " 'faults',\n",
       " 'unknown',\n",
       " 'brighter',\n",
       " 'paper',\n",
       " 'touched',\n",
       " 'Patrick',\n",
       " 'Alexandria',\n",
       " 'corpse',\n",
       " 'tying',\n",
       " 'consulted',\n",
       " 'examined',\n",
       " 'prove',\n",
       " 'cajoled',\n",
       " 'chair',\n",
       " 'persuaded',\n",
       " 'happen',\n",
       " 'disapproved',\n",
       " 'ill-',\n",
       " 'undoubtedly',\n",
       " 'birthday',\n",
       " 'promises',\n",
       " 'mis-',\n",
       " 'depends',\n",
       " '16',\n",
       " 'Mark',\n",
       " 'fewer',\n",
       " 'instinct',\n",
       " 'trait',\n",
       " 'Sarah',\n",
       " 'barred',\n",
       " 'actors',\n",
       " 'uncertain',\n",
       " 'events',\n",
       " 'abstract',\n",
       " 'torment',\n",
       " 'ahead',\n",
       " 'color',\n",
       " 'merely',\n",
       " 'device',\n",
       " 'resentment',\n",
       " 'interfered',\n",
       " 'premature',\n",
       " 'luck',\n",
       " 'victorious',\n",
       " 'unparalleled',\n",
       " 'absence',\n",
       " 'saturated',\n",
       " 'reader',\n",
       " 'disgraceful',\n",
       " 'respectful',\n",
       " 'hardness',\n",
       " 'trustful',\n",
       " 'performing',\n",
       " 'breeding',\n",
       " 'constituted',\n",
       " 'scruples',\n",
       " 'porter',\n",
       " 'jumped',\n",
       " 'forced',\n",
       " 'moods',\n",
       " 'prophet',\n",
       " 'wrath',\n",
       " 'Passing',\n",
       " 'self-chosen',\n",
       " 'regiment',\n",
       " 'genuinely',\n",
       " 'hasten',\n",
       " 'high-spirited',\n",
       " 'masters',\n",
       " 'Countess',\n",
       " 'Opera',\n",
       " 'illumined',\n",
       " 'forgot',\n",
       " 'relinquished',\n",
       " 'win',\n",
       " 'love-letters',\n",
       " 'wait',\n",
       " 'peculiarities',\n",
       " 'enjoying',\n",
       " 'fireside',\n",
       " 'resort',\n",
       " 'combine',\n",
       " 'headed',\n",
       " 'flying',\n",
       " 'etc.',\n",
       " 'commonplace',\n",
       " 'Juan',\n",
       " 'dayâ\\x80\\x94',\n",
       " 'driving',\n",
       " 'blade',\n",
       " 'amiss',\n",
       " 'sanctuary',\n",
       " 'protracted',\n",
       " 'bravo',\n",
       " 'lodged',\n",
       " 'await',\n",
       " 'issue',\n",
       " 'ally',\n",
       " ...]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primary_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
