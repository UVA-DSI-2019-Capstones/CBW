{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings for Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required packages\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the working directory\n",
    "os.chdir('E:/Capstone IATH/Code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "bess_data = pd.read_csv('CBW_Bess_tags_final2.csv', encoding='ISO-8859-1', low_memory=False)\n",
    "text_features = pd.read_csv('text_features.csv', encoding='ISO-8859-1', low_memory=False)\n",
    "text_topics = pd.read_csv('text_data_sentence_wtopics.csv', encoding='ISO-8859-1', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating unique identifier for each row: CollectionID + BiographyID + ParagraphNo\n",
    "text_features['key'] = text_features['CollectionID'].astype(str) + '_' + text_features['BiographyID'].astype(str) +'_' + text_features['ParagraphNo'].astype(str)\n",
    "\n",
    "# Using sentiment, emotion, topics as features along with text\n",
    "text_features.drop(columns=['CollectionID', 'BiographyID', 'ParagraphNo', 'Anatomy', 'Award', 'Company', 'Date', 'Drug', 'Measure', 'Movie', 'Number', 'Quantity', 'Sport', 'SportingEvent', 'TelevisionShow', 'Time', 'Vehicle', 'Crime', 'Facility', 'GeographicFeature', 'HealthCondition', 'JobTitle', 'Location', 'Organization', 'Person', 'PrintMedia'], inplace=True)\n",
    "\n",
    "# Rearranging the columns\n",
    "text_features = text_features[['key', 'ParagraphText', 'score', 'sentiment', 'sadness', 'joy', 'fear', 'disgust', 'anger']]\n",
    "\n",
    "sentiment = pd.get_dummies(text_features['sentiment'])\n",
    "text_features = pd.concat([text_features, sentiment], axis=1)\n",
    "text_features.drop(columns=['sentiment'], inplace=True)\n",
    "\n",
    "# Adding topics\n",
    "text_features['Topic 0'] = text_topics['Topic 0']\n",
    "text_features['Topic 1'] = text_topics['Topic 1']\n",
    "text_features['Topic 2'] = text_topics['Topic 2']\n",
    "text_features['Topic 3'] = text_topics['Topic 3']\n",
    "text_features['Topic 4'] = text_topics['Topic 4']\n",
    "text_features['Topic 5'] = text_topics['Topic 5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Varshini\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\Varshini\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3778: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  return super(DataFrame, self).rename(**kwargs)\n",
      "C:\\Users\\Varshini\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\Varshini\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3694: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "#Preparing the data for stage of life classification\n",
    "#Converting bess_data so that each row is a para in a bio\n",
    "#Taking into stage of life for now\n",
    "stage_of_life = bess_data[bess_data.Type == 'stageOfLife']\n",
    "stage_of_life['para no'] = stage_of_life['para no'].astype(int)\n",
    "stage_of_life.rename(index=str, columns={\"collectionID\": \"CollectionID\", \"biographyID\": \"BiographyID\", \"para no\": \"ParagraphNo\", \"Content\": \"StageOfLife\"}, inplace=True)\n",
    "\n",
    "#Creating unique identifier for each row: CollectionID + BiographyID + ParagraphNo\n",
    "stage_of_life['key'] = stage_of_life['CollectionID'].astype(str) + '_' + stage_of_life['BiographyID'].astype(str) +'_' + stage_of_life['ParagraphNo'].astype(str)\n",
    "\n",
    "#Removing other columns\n",
    "stage_of_life.drop(columns=['Event', 'Type', 'URI', 'author', 'personaName', 'title', 'CollectionID', 'BiographyID', 'ParagraphNo'], inplace=True)\n",
    "\n",
    "stage_of_life = stage_of_life[['key', 'StageOfLife']]\n",
    "stage_of_life.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "middle         8459\n",
       "culmination    2695\n",
       "beginning      2365\n",
       "end            1019\n",
       "after           777\n",
       "before          213\n",
       "Name: StageOfLife, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage_of_life.StageOfLife.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the response variable\n",
    "stage_of_life['StageOfLife'] = stage_of_life['StageOfLife'].astype('category')\n",
    "stage = pd.get_dummies(stage_of_life['StageOfLife'])\n",
    "stage_of_life = pd.concat([stage_of_life, stage], axis=1)\n",
    "stage_of_life.drop(columns=['StageOfLife'], inplace=True)\n",
    "stage_of_life.drop_duplicates(inplace=True)\n",
    "stage_of_life = stage_of_life.groupby(['key'])['after', 'before', 'beginning', 'culmination', 'end', 'middle'].sum()\n",
    "stage_of_life['key'] = stage_of_life.index\n",
    "stage_of_life = stage_of_life[['key', 'after', 'before', 'beginning', 'culmination', 'end', 'middle']]\n",
    "stage_of_life.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_bess = pd.merge(text_features, stage_of_life, how='right', on=['key'])\n",
    "text_bess.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Processing\n",
    "text_bess['ParagraphText'] = text_bess['ParagraphText'].astype(str)\n",
    "\n",
    "#Converting to lower case\n",
    "text_bess['ParagraphText'] = text_bess['ParagraphText'].str.lower()\n",
    "\n",
    "#Tokenizing the text in the data\n",
    "wpt = nltk.WordPunctTokenizer()\n",
    "text_bess['tokenized'] = text_bess['ParagraphText'].apply(lambda x: wpt.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keeping only words\n",
    "text_bess['tokenized'] = text_bess['tokenized'].apply(lambda x: [i for i in x if i.isalpha()])\n",
    "\n",
    "#Removing stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words=set(stopwords.words(\"english\"))\n",
    "text_bess['tokenized'] = text_bess['tokenized'].apply(lambda x: [i for i in x if not i in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "text_bess['tokenized'] = text_bess['tokenized'].apply(lambda x: [wordnet_lemmatizer.lemmatize(i) for i in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating word embeddings for train and test data\n",
    "we = word2vec.Word2Vec(text_bess['tokenized'], size=300, min_count=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_word_vectors(words, model, vocabulary, num_features):\n",
    "    \n",
    "    feature_vector = np.zeros((num_features,),dtype=\"float64\")\n",
    "    nwords = 0.\n",
    "    \n",
    "    for word in words:\n",
    "        if word in vocabulary: \n",
    "            nwords = nwords + 1.\n",
    "            feature_vector = np.add(feature_vector, model[word])\n",
    "    \n",
    "    if nwords:\n",
    "        feature_vector = np.divide(feature_vector, nwords)\n",
    "        \n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def averaged_word_vectorizer(corpus, model, num_features):\n",
    "    vocabulary = set(we.wv.index2word)\n",
    "    features = [average_word_vectors(tokenized_sentence, model, vocabulary, num_features)\n",
    "                    for tokenized_sentence in corpus]\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Varshini\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "#Word embedded features for train and test\n",
    "feature_array = averaged_word_vectorizer(corpus=text_bess['tokenized'], model=we,\n",
    "                                             num_features=300)\n",
    "wefeatures = pd.DataFrame(feature_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final data\n",
    "final_data = pd.concat([wefeatures, text_bess], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.drop(columns = ['key', 'ParagraphText', 'tokenized'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14923, 321)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and response\n",
    "X = final_data.iloc[:,0:315]\n",
    "Y = final_data.iloc[:,315:321]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['after', 'before', 'beginning', 'culmination', 'end', 'middle'], dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate models for each stage of life (binary classification)\n",
    "Y_1 = Y['after']\n",
    "Y_2 = Y['before']\n",
    "Y_3 = Y['beginning']\n",
    "Y_4 = Y['culmination']\n",
    "Y_5 = Y['end']\n",
    "Y_6 = Y['middle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9504187604690117\n"
     ]
    }
   ],
   "source": [
    "# classification model for after\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y_1, test_size = 0.2, random_state = 0)\n",
    "rf_model.fit(x_train, y_train)\n",
    "predictions_after = rf_model.predict(x_test)\n",
    "print(accuracy_score(y_test, predictions_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2835, 2, 146, 2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions_after).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9899497487437185\n"
     ]
    }
   ],
   "source": [
    "# classification model for before\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y_2, test_size = 0.2, random_state = 0)\n",
    "rf_model.fit(x_train, y_train)\n",
    "predictions_before = rf_model.predict(x_test)\n",
    "print(accuracy_score(y_test, predictions_before))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2955, 0, 30, 0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions_before).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8559463986599665\n"
     ]
    }
   ],
   "source": [
    "# classification model for beginning\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y_3, test_size = 0.2, random_state = 0)\n",
    "rf_model.fit(x_train, y_train)\n",
    "predictions_beginning = rf_model.predict(x_test)\n",
    "print(accuracy_score(y_test, predictions_beginning))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2502, 28, 402, 53)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions_beginning).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.847571189279732\n"
     ]
    }
   ],
   "source": [
    "# classification model for culmination\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y_4, test_size = 0.2, random_state = 0)\n",
    "rf_model.fit(x_train, y_train)\n",
    "predictions_culmination = rf_model.predict(x_test)\n",
    "print(accuracy_score(y_test, predictions_culmination))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2455, 15, 440, 75)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions_culmination).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9463986599664992\n"
     ]
    }
   ],
   "source": [
    "# classification model for end\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y_5, test_size = 0.2, random_state = 0)\n",
    "rf_model.fit(x_train, y_train)\n",
    "predictions_end = rf_model.predict(x_test)\n",
    "print(accuracy_score(y_test, predictions_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2805, 3, 157, 20)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions_end).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6422110552763819\n"
     ]
    }
   ],
   "source": [
    "# classification model for middle\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y_6, test_size = 0.2, random_state = 0)\n",
    "rf_model.fit(x_train, y_train)\n",
    "predictions_middle = rf_model.predict(x_test)\n",
    "print(accuracy_score(y_test, predictions_middle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(526, 675, 393, 1391)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions_middle).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7581239530988275\n"
     ]
    }
   ],
   "source": [
    "# classification model for after\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y_1, test_size = 0.2, random_state = 0)\n",
    "nb_model.fit(x_train, y_train)\n",
    "predictions_after = nb_model.predict(x_test)\n",
    "print(accuracy_score(y_test, predictions_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2201, 636, 86, 62)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions_after).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6026800670016751\n"
     ]
    }
   ],
   "source": [
    "# classification model for before\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y_2, test_size = 0.2, random_state = 0)\n",
    "nb_model.fit(x_train, y_train)\n",
    "predictions_before = nb_model.predict(x_test)\n",
    "print(accuracy_score(y_test, predictions_before))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1774, 1181, 5, 25)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions_before).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6636515912897822\n"
     ]
    }
   ],
   "source": [
    "# classification model for beginning\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y_3, test_size = 0.2, random_state = 0)\n",
    "nb_model.fit(x_train, y_train)\n",
    "predictions_beginning = nb_model.predict(x_test)\n",
    "print(accuracy_score(y_test, predictions_beginning))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1733, 797, 207, 248)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions_beginning).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5748743718592965\n"
     ]
    }
   ],
   "source": [
    "# classification model for culmination\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y_4, test_size = 0.2, random_state = 0)\n",
    "nb_model.fit(x_train, y_train)\n",
    "predictions_culmination = nb_model.predict(x_test)\n",
    "print(accuracy_score(y_test, predictions_culmination))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1437, 1033, 236, 279)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions_culmination).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7675041876046901\n"
     ]
    }
   ],
   "source": [
    "# classification model for end\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y_5, test_size = 0.2, random_state = 0)\n",
    "nb_model.fit(x_train, y_train)\n",
    "predictions_end = nb_model.predict(x_test)\n",
    "print(accuracy_score(y_test, predictions_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2213, 595, 99, 78)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions_end).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5916247906197655\n"
     ]
    }
   ],
   "source": [
    "# classification model for middle\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y_6, test_size = 0.2, random_state = 0)\n",
    "nb_model.fit(x_train, y_train)\n",
    "predictions_middle = nb_model.predict(x_test)\n",
    "print(accuracy_score(y_test, predictions_middle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(883, 318, 1429, 355)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions_end).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Support Vector Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVC with SGD\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_model = SGDClassifier(max_iter=1000, tol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9504187604690117\n"
     ]
    }
   ],
   "source": [
    "# classification model for after\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y_1, test_size = 0.2, random_state = 0)\n",
    "sv_model.fit(x_train, y_train)\n",
    "predictions_after = sv_model.predict(x_test)\n",
    "print(accuracy_score(y_test, predictions_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9899497487437185\n"
     ]
    }
   ],
   "source": [
    "# classification model for before\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y_2, test_size = 0.2, random_state = 0)\n",
    "sv_model.fit(x_train, y_train)\n",
    "predictions_before = sv_model.predict(x_test)\n",
    "print(accuracy_score(y_test, predictions_before))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.847571189279732\n"
     ]
    }
   ],
   "source": [
    "# classification model for beginning\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y_3, test_size = 0.2, random_state = 0)\n",
    "sv_model.fit(x_train, y_train)\n",
    "predictions_beginning = sv_model.predict(x_test)\n",
    "print(accuracy_score(y_test, predictions_beginning))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8274706867671692\n"
     ]
    }
   ],
   "source": [
    "# classification model for culmination\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y_4, test_size = 0.2, random_state = 0)\n",
    "sv_model.fit(x_train, y_train)\n",
    "predictions_culmination = sv_model.predict(x_test)\n",
    "print(accuracy_score(y_test, predictions_culmination))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9407035175879397\n"
     ]
    }
   ],
   "source": [
    "# classification model for end\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y_5, test_size = 0.2, random_state = 0)\n",
    "sv_model.fit(x_train, y_train)\n",
    "predictions_end = sv_model.predict(x_test)\n",
    "print(accuracy_score(y_test, predictions_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6093802345058627\n"
     ]
    }
   ],
   "source": [
    "# classification model for middle\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y_6, test_size = 0.2, random_state = 0)\n",
    "sv_model.fit(x_train, y_train)\n",
    "predictions_middle = sv_model.predict(x_test)\n",
    "print(accuracy_score(y_test, predictions_middle))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
